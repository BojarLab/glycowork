{
 "cells": [
  {
   "cell_type": "raw",
   "id": "constitutional-clock",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ml.html\n",
    "title: ml\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| default_exp ml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nbdev.showdoc import show_doc\n",
    "from IPython.display import HTML\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from glycowork.ml.models import *\n",
    "from glycowork.ml.inference import *\n",
    "from glycowork.ml.processing import *\n",
    "from glycowork.ml.model_training import *\n",
    "from glycowork.ml.train_test_split import *\n",
    "from glycowork.glycan_data.loader import df_species, df_glycan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-burden",
   "metadata": {},
   "source": [
    "`ml` contains the code base to process glycan for machine learning, construct state-of-the-art machine learning models, train them, and analyze trained models + glycan representations. It currently contains the following modules:\n",
    "\n",
    "- `model_training` contains functions for training machine learning models\n",
    "- `models` describes some examples for machine learning architectures applicable to glycans\n",
    "- `processing` contains helper functions to prepare glycan data for model training\n",
    "- `inference` can be used to analyze trained models, make predictions, or obtain glycan representations\n",
    "- `train_test_split` contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-finland",
   "metadata": {},
   "source": [
    "## model_training\n",
    ">contains functions for training machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience:int=7, verbose:bool=False)\n",
       "\n",
       "*Early stops the training if validation loss doesn't improve after a given patience*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| patience | int | 7 | epochs to wait after last improvement |\n",
       "| verbose | bool | False | whether to print messages |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### EarlyStopping\n",
       "\n",
       ">      EarlyStopping (patience:int=7, verbose:bool=False)\n",
       "\n",
       "*Early stops the training if validation loss doesn't improve after a given patience*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| patience | int | 7 | epochs to wait after last improvement |\n",
       "| verbose | bool | False | whether to print messages |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model:torch.nn.modules.module.Module,\n",
       ">                   dataloaders:Dict[str,torch.utils.data.dataloader.DataLoader]\n",
       ">                   , criterion:torch.nn.modules.module.Module,\n",
       ">                   optimizer:torch.optim.optimizer.Optimizer,\n",
       ">                   scheduler:torch.optim.lr_scheduler._LRScheduler,\n",
       ">                   num_epochs:int=25, patience:int=50,\n",
       ">                   mode:str='classification', mode2:str='multi',\n",
       ">                   return_metrics:bool=False)\n",
       "\n",
       "*trains a deep learning model on predicting glycan properties*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | graph neural network for analyzing glycans |\n",
       "| dataloaders | Dict |  | dict with 'train' and 'val' loaders |\n",
       "| criterion | Module |  | PyTorch loss function |\n",
       "| optimizer | Optimizer |  | PyTorch optimizer, has to be SAM if mode != \"regression\" |\n",
       "| scheduler | _LRScheduler |  | PyTorch learning rate decay |\n",
       "| num_epochs | int | 25 | number of epochs for training |\n",
       "| patience | int | 50 | epochs without improvement until early stop |\n",
       "| mode | str | classification | 'classification', 'multilabel', or 'regression' |\n",
       "| mode2 | str | multi | 'multi' or 'binary' classification |\n",
       "| return_metrics | bool | False | whether to return metrics |\n",
       "| **Returns** | **Union** |  | **best model from training and the training and validation metrics** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_model\n",
       "\n",
       ">      train_model (model:torch.nn.modules.module.Module,\n",
       ">                   dataloaders:Dict[str,torch.utils.data.dataloader.DataLoader]\n",
       ">                   , criterion:torch.nn.modules.module.Module,\n",
       ">                   optimizer:torch.optim.optimizer.Optimizer,\n",
       ">                   scheduler:torch.optim.lr_scheduler._LRScheduler,\n",
       ">                   num_epochs:int=25, patience:int=50,\n",
       ">                   mode:str='classification', mode2:str='multi',\n",
       ">                   return_metrics:bool=False)\n",
       "\n",
       "*trains a deep learning model on predicting glycan properties*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | graph neural network for analyzing glycans |\n",
       "| dataloaders | Dict |  | dict with 'train' and 'val' loaders |\n",
       "| criterion | Module |  | PyTorch loss function |\n",
       "| optimizer | Optimizer |  | PyTorch optimizer, has to be SAM if mode != \"regression\" |\n",
       "| scheduler | _LRScheduler |  | PyTorch learning rate decay |\n",
       "| num_epochs | int | 25 | number of epochs for training |\n",
       "| patience | int | 50 | epochs without improvement until early stop |\n",
       "| mode | str | classification | 'classification', 'multilabel', or 'regression' |\n",
       "| mode2 | str | multi | 'multi' or 'binary' classification |\n",
       "| return_metrics | bool | False | whether to return metrics |\n",
       "| **Returns** | **Union** |  | **best model from training and the training and validation metrics** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-taxation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model:torch.nn.modules.module.Module, lr:float,\n",
       ">                      lr_patience:int=4, factor:float=0.2,\n",
       ">                      weight_decay:float=0.0001, mode:str='multiclass',\n",
       ">                      num_classes:int=2, gsam_alpha:float=0.0)\n",
       "\n",
       "*prepares optimizer, learning rate scheduler, and loss criterion for model training*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | graph neural network for analyzing glycans |\n",
       "| lr | float |  | learning rate |\n",
       "| lr_patience | int | 4 | epochs before reducing learning rate |\n",
       "| factor | float | 0.2 | factor to multiply lr on reduction |\n",
       "| weight_decay | float | 0.0001 | regularization parameter |\n",
       "| mode | str | multiclass | type of prediction task |\n",
       "| num_classes | int | 2 | number of classes for classification |\n",
       "| gsam_alpha | float | 0.0 | if >0, uses GSAM instead of SAM optimizer |\n",
       "| **Returns** | **Tuple** |  | **optimizer, scheduler, criterion** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### training_setup\n",
       "\n",
       ">      training_setup (model:torch.nn.modules.module.Module, lr:float,\n",
       ">                      lr_patience:int=4, factor:float=0.2,\n",
       ">                      weight_decay:float=0.0001, mode:str='multiclass',\n",
       ">                      num_classes:int=2, gsam_alpha:float=0.0)\n",
       "\n",
       "*prepares optimizer, learning rate scheduler, and loss criterion for model training*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | graph neural network for analyzing glycans |\n",
       "| lr | float |  | learning rate |\n",
       "| lr_patience | int | 4 | epochs before reducing learning rate |\n",
       "| factor | float | 0.2 | factor to multiply lr on reduction |\n",
       "| weight_decay | float | 0.0001 | regularization parameter |\n",
       "| mode | str | multiclass | type of prediction task |\n",
       "| num_classes | int | 2 | number of classes for classification |\n",
       "| gsam_alpha | float | 0.0 | if >0, uses GSAM instead of SAM optimizer |\n",
       "| **Returns** | **Tuple** |  | **optimizer, scheduler, criterion** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(training_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train:Union[pandas.core.frame.DataFrame,List],\n",
       ">                      X_test:Union[pandas.core.frame.DataFrame,List],\n",
       ">                      y_train:List, y_test:List, mode:str='classification',\n",
       ">                      feature_calc:bool=False, return_features:bool=False,\n",
       ">                      feature_set:List[str]=['known', 'exhaustive'], additional\n",
       ">                      _features_train:Optional[pandas.core.frame.DataFrame]=Non\n",
       ">                      e, additional_features_test:Optional[pandas.core.frame.Da\n",
       ">                      taFrame]=None)\n",
       "\n",
       "*wrapper function to train standard machine learning models on glycans*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_train | Union |  | training data/glycans |\n",
       "| X_test | Union |  | test data/glycans |\n",
       "| y_train | List |  | training labels |\n",
       "| y_test | List |  | test labels |\n",
       "| mode | str | classification | 'classification' or 'regression' |\n",
       "| feature_calc | bool | False | calculate motifs from glycans |\n",
       "| return_features | bool | False | return calculated features |\n",
       "| feature_set | List | ['known', 'exhaustive'] | feature set for annotations |\n",
       "| additional_features_train | Optional | None | additional training features |\n",
       "| additional_features_test | Optional | None | additional test features |\n",
       "| **Returns** | **Union** |  | **trained model and optionally features** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### train_ml_model\n",
       "\n",
       ">      train_ml_model (X_train:Union[pandas.core.frame.DataFrame,List],\n",
       ">                      X_test:Union[pandas.core.frame.DataFrame,List],\n",
       ">                      y_train:List, y_test:List, mode:str='classification',\n",
       ">                      feature_calc:bool=False, return_features:bool=False,\n",
       ">                      feature_set:List[str]=['known', 'exhaustive'], additional\n",
       ">                      _features_train:Optional[pandas.core.frame.DataFrame]=Non\n",
       ">                      e, additional_features_test:Optional[pandas.core.frame.Da\n",
       ">                      taFrame]=None)\n",
       "\n",
       "*wrapper function to train standard machine learning models on glycans*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_train | Union |  | training data/glycans |\n",
       "| X_test | Union |  | test data/glycans |\n",
       "| y_train | List |  | training labels |\n",
       "| y_test | List |  | test labels |\n",
       "| mode | str | classification | 'classification' or 'regression' |\n",
       "| feature_calc | bool | False | calculate motifs from glycans |\n",
       "| return_features | bool | False | return calculated features |\n",
       "| feature_set | List | ['known', 'exhaustive'] | feature set for annotations |\n",
       "| additional_features_train | Optional | None | additional training features |\n",
       "| additional_features_test | Optional | None | additional test features |\n",
       "| **Returns** | **Union** |  | **trained model and optionally features** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(train_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-knock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You provided glycans without features but did not specify feature_calc; we'll step in and calculate features with the default feature_set but feel free to re-run and change.\n",
      "\n",
      "Calculating Glycan Features...\n",
      "\n",
      "Training model...\n",
      "\n",
      "Evaluating model...\n",
      "Accuracy of trained model on separate validation set: 0.8722222222222222\n"
     ]
    }
   ],
   "source": [
    "human = [1 if k == 'Homo_sapiens' else 0 for k in df_species[df_species.Order=='Primates'].Species.values.tolist()]\n",
    "X_train, X_test, y_train, y_test = general_split(df_species[df_species.Order=='Primates'].glycan.values.tolist(), human)\n",
    "model_ft, _, X_test = train_ml_model(X_train, X_test, y_train, y_test, feature_calc = True, feature_set = ['terminal'],\n",
    "                         return_features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-lover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model:xgboost.sklearn.XGBModel)\n",
       "\n",
       "*plots relevant features for model prediction*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| model | XGBModel | trained ML model from train_ml_model |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### analyze_ml_model\n",
       "\n",
       ">      analyze_ml_model (model:xgboost.sklearn.XGBModel)\n",
       "\n",
       "*plots relevant features for model prediction*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| model | XGBModel | trained ML model from train_ml_model |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(analyze_ml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-holmes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAHWCAYAAADDx3XRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2WklEQVR4nO3dd1QUV/8G8GcXpEgXBQSVooiIXWI09l5if6OxRAU1lpgYuxJjwa55Y48ae2Js2GKNiWKLvWIviCjR2FEUEBS4vz982Z8b0LDN2Zl9PudwjjszLM+Fvd7v3GkqIYQAEREREZkNtdQBiIiIiEgbCzQiIiIiM8MCjYiIiMjMsEAjIiIiMjMs0IiIiIjMDAs0IiIiIjPDAo2IiIjIzLBAIyIiIjIzLNCIiIiIzAwLNCIiIiIzwwKNyEIsX74cKpUq168RI0aY5GcePnwYY8eOxdOnT03y/obI/n2cPHlS6ih6mzdvHpYvXy51DCIyAWupAxDR+zVu3Dj4+/trLStTpoxJftbhw4cRGRmJsLAwuLq6muRnWLJ58+ahYMGCCAsLkzoKERkZCzQiC9O0aVOEhoZKHcMgKSkpcHBwkDqGZFJTU5E/f36pYxCRCfEQJxFp+e2331CzZk04ODjAyckJH3/8MS5evKi1zblz5xAWFoaAgADY2dnBy8sL3bt3x+PHjzXbjB07FkOHDgUA+Pv7aw6n3rx5Ezdv3oRKpcr18JxKpcLYsWO13kelUuHSpUvo1KkT3NzcUKNGDc36X375BZUrV4a9vT0KFCiADh064K+//tKr7WFhYXB0dERCQgKaN28OR0dH+Pj44IcffgAAnD9/HvXq1YODgwN8fX2xatUqre/PPmx64MAB9O7dG+7u7nB2dkbXrl3x5MmTHD9v3rx5CAkJga2tLby9vdGvX78ch4Pr1KmDMmXK4NSpU6hVqxby58+Pb775Bn5+frh48SL279+v+d3WqVMHAJCYmIghQ4agbNmycHR0hLOzM5o2bYqzZ89qvfe+ffugUqkQFRWFiRMnokiRIrCzs0P9+vVx/fr1HHmPHTuGZs2awc3NDQ4ODihXrhxmzZqltc2VK1fwySefoECBArCzs0NoaCi2bNmi65+CyOJxBo3IwiQlJeHRo0daywoWLAgAWLFiBbp164bGjRtj6tSpSE1Nxfz581GjRg2cOXMGfn5+AIBdu3bhxo0bCA8Ph5eXFy5evIiFCxfi4sWLOHr0KFQqFdq2bYtr165h9erVmDFjhuZnFCpUCA8fPtQ5d7t27RAYGIhJkyZBCAEAmDhxIkaNGoX27dujZ8+eePjwIebMmYNatWrhzJkzeh1WzczMRNOmTVGrVi1MmzYNK1euxJdffgkHBweMHDkSnTt3Rtu2bbFgwQJ07doV1apVy3HI+Msvv4SrqyvGjh2Lq1evYv78+bh165amIAJeF56RkZFo0KAB+vbtq9nuxIkTOHToEPLly6d5v8ePH6Np06bo0KEDPvvsM3h6eqJOnTr46quv4OjoiJEjRwIAPD09AQA3btzAr7/+inbt2sHf3x/379/Hjz/+iNq1a+PSpUvw9vbWyjtlyhSo1WoMGTIESUlJmDZtGjp37oxjx45pttm1axeaN2+OwoUL4+uvv4aXlxcuX76Mbdu24euvvwYAXLx4EdWrV4ePjw9GjBgBBwcHREVFoXXr1tiwYQPatGmj89+DyGIJIrIIy5YtEwBy/RJCiOfPnwtXV1fx+eefa33fvXv3hIuLi9by1NTUHO+/evVqAUAcOHBAs+y7774TAER8fLzWtvHx8QKAWLZsWY73ASDGjBmjeT1mzBgBQHTs2FFru5s3bworKysxceJEreXnz58X1tbWOZa/7fdx4sQJzbJu3boJAGLSpEmaZU+ePBH29vZCpVKJNWvWaJZfuXIlR9bs96xcubJ4+fKlZvm0adMEALF582YhhBAPHjwQNjY2olGjRiIzM1Oz3dy5cwUAsXTpUs2y2rVrCwBiwYIFOdoQEhIiateunWN5Wlqa1vsK8fp3bmtrK8aNG6dZtnfvXgFABAcHi/T0dM3yWbNmCQDi/PnzQgghMjIyhL+/v/D19RVPnjzRet+srCzNv+vXry/Kli0r0tLStNZ/9NFHIjAwMEdOIno7HuIksjA//PADdu3apfUFvJ4hefr0KTp27IhHjx5pvqysrPDhhx9i7969mvewt7fX/DstLQ2PHj1C1apVAQCnT582Se4+ffpovd64cSOysrLQvn17rbxeXl4IDAzUyqurnj17av7t6uqKoKAgODg4oH379prlQUFBcHV1xY0bN3J8f69evbRmwPr27Qtra2vs2LEDALB79268fPkSAwYMgFr9//8Nf/7553B2dsb27du13s/W1hbh4eF5zm9ra6t538zMTDx+/BiOjo4ICgrK9e8THh4OGxsbzeuaNWsCgKZtZ86cQXx8PAYMGJBjVjJ7RjAxMRF79uxB+/bt8fz5c83f4/Hjx2jcuDFiY2Nx586dPLeByNLxECeRhalSpUquFwnExsYCAOrVq5fr9zk7O2v+nZiYiMjISKxZswYPHjzQ2i4pKcmIaf/fPw8jxsbGQgiBwMDAXLd/s0DShZ2dHQoVKqS1zMXFBUWKFNEUI28uz+3csn9mcnR0ROHChXHz5k0AwK1btwC8LvLeZGNjg4CAAM36bD4+PloF1L/JysrCrFmzMG/ePMTHxyMzM1Ozzt3dPcf2xYoV03rt5uYGAJq2xcXFAXj31b7Xr1+HEAKjRo3CqFGjct3mwYMH8PHxyXM7iCwZCzQiAvB6UAden4fm5eWVY7219f//d9G+fXscPnwYQ4cORYUKFeDo6IisrCw0adJE8z7v8s9CJ9ubhcQ/vTlrl51XpVLht99+g5WVVY7tHR0d/zVHbnJ7r3ctF/87H86U/tn2fzNp0iSMGjUK3bt3x/jx41GgQAGo1WoMGDAg17+PMdqW/b5DhgxB48aNc92mRIkSeX4/IkvHAo2IAADFixcHAHh4eKBBgwZv3e7JkyeIjo5GZGQkRo8erVmePQP3prcVYtkzNP+8YvGfM0f/llcIAX9/f5QsWTLP3/c+xMbGom7duprXycnJuHv3Lpo1awYA8PX1BQBcvXoVAQEBmu1evnyJ+Pj4d/7+3/S23+/69etRt25dLFmyRGv506dPNRdr6CL7s3HhwoW3ZstuR758+fKcn4jejuegEREAoHHjxnB2dsakSZPw6tWrHOuzr7zMnm355+zKzJkzc3xP9r3K/lmIOTs7o2DBgjhw4IDW8nnz5uU5b9u2bWFlZYXIyMgcWYQQWrf8eN8WLlyo9TucP38+MjIy0LRpUwBAgwYNYGNjg9mzZ2tlX7JkCZKSkvDxxx/n6ec4ODjk+pQGKyurHL+TdevW6X0OWKVKleDv74+ZM2fm+HnZP8fDwwN16tTBjz/+iLt37+Z4D32u3CWyZJxBIyIAr4um+fPno0uXLqhUqRI6dOiAQoUKISEhAdu3b0f16tUxd+5cODs7a25B8erVK/j4+OCPP/5AfHx8jvesXLkyAGDkyJHo0KED8uXLhxYtWsDBwQE9e/bElClT0LNnT4SGhuLAgQO4du1anvMWL14cEyZMQEREBG7evInWrVvDyckJ8fHx2LRpE3r16oUhQ4YY7feji5cvX6J+/fpo3749rl69innz5qFGjRpo2bIlgNe3GomIiEBkZCSaNGmCli1barb74IMP8Nlnn+Xp51SuXBnz58/HhAkTUKJECXh4eKBevXpo3rw5xo0bh/DwcHz00Uc4f/48Vq5cqTVbpwu1Wo358+ejRYsWqFChAsLDw1G4cGFcuXIFFy9exO+//w7g9QUoNWrUQNmyZfH5558jICAA9+/fx5EjR3D79u0c92EjoneQ6OpRInrPcrutRG727t0rGjduLFxcXISdnZ0oXry4CAsLEydPntRsc/v2bdGmTRvh6uoqXFxcRLt27cTff/+d47YTQggxfvx44ePjI9RqtdYtN1JTU0WPHj2Ei4uLcHJyEu3btxcPHjx46202Hj58mGveDRs2iBo1aggHBwfh4OAgSpUqJfr16yeuXr2q8++jW7duwsHBIce2tWvXFiEhITmW+/r6io8//jjHe+7fv1/06tVLuLm5CUdHR9G5c2fx+PHjHN8/d+5cUapUKZEvXz7h6ekp+vbtm+M2Fm/72UK8vgXKxx9/LJycnAQAzS030tLSxODBg0XhwoWFvb29qF69ujhy5IioXbu21m05sm+zsW7dOq33fdttUA4ePCgaNmwonJychIODgyhXrpyYM2eO1jZxcXGia9euwsvLS+TLl0/4+PiI5s2bi/Xr1+faBiLKnUqI93CGKxGRBVi+fDnCw8Nx4sQJ2T9Oi4ikxXPQiIiIiMwMCzQiIiIiM8MCjYiIiMjM8Bw0IiIiIjPDGTQiIiIiMyNpgTZ58mR88MEHcHJygoeHB1q3bo2rV69qbZOWloZ+/frB3d0djo6O+M9//oP79+9LlJiIiIjI9CQt0Pbv349+/frh6NGj2LVrF169eoVGjRohJSVFs83AgQOxdetWrFu3Dvv378fff/+Ntm3bSpiaiIiIyLTM6hy0hw8fwsPDA/v370etWrWQlJSEQoUKYdWqVfjkk08AAFeuXEFwcDCOHDmCqlWrSpyYiIiIyPjM6hy0pKQkAECBAgUAAKdOncKrV6+0HrxbqlQpFCtWDEeOHMn1PdLT0/Hs2TOtr/T0dNOHJyIiIjISsynQsrKyMGDAAFSvXh1lypQBANy7dw82NjZwdXXV2tbT0xP37t3L9X0mT54MFxcXra/JkyebOj4RERGR0ZjNw9L79euHCxcu4ODBgwa9T0REBAYNGqS1zNbW1qD3JCIiInqfzKJA+/LLL7Ft2zYcOHAARYoU0Sz38vLCy5cv8fTpU61ZtPv378PLyyvX97K1tWVBRkRERLIm6SFOIQS+/PJLbNq0CXv27IG/v7/W+sqVKyNfvnyIjo7WLLt69SoSEhJQrVq19x2XiIiI6L2Q9CrOL774AqtWrcLmzZsRFBSkWe7i4gJ7e3sAQN++fbFjxw4sX74czs7O+OqrrwAAhw8fliQzERERkalJWqCpVKpcly9btgxhYWEAXt+odvDgwVi9ejXS09PRuHFjzJs3762HOImIiIjkzqzug0ZEREREZnSbDSIiIiJ6jQUaERERkZlhgUZERERkZsziPmhSGLYoTuoIOpn2eXGpIxAREdF7whk0IiIiIjPDAo2IiIjIzLBAIyIiIjIzLNCIiIiIzAwLNCIiIiIzwwKNiIiIyMywQCMiIiIyMyzQiIiIiMwMCzQiIiIiM8MCjYiIiMjMsEAjIiIiMjMs0IiIiIjMDAs0IiIiIjPDAo2IiIjIzFjr802vXr3CvXv3kJqaikKFCqFAgQLGzkVERERksfI8g/b8+XPMnz8ftWvXhrOzM/z8/BAcHIxChQrB19cXn3/+OU6cOGHKrEREREQWIU8F2vTp0+Hn54dly5ahQYMG+PXXXxETE4Nr167hyJEjGDNmDDIyMtCoUSM0adIEsbGxps5NREREpFh5OsR54sQJHDhwACEhIbmur1KlCrp3744FCxZg2bJl+PPPPxEYGGjUoERERESWQiWEEFKHkMKwRXFSR9DJtM+LSx2BiIiI3hNexUlERERkZnS+ijMlJQVTpkxBdHQ0Hjx4gKysLK31N27cMFo4IiIiIkukc4HWs2dP7N+/H126dEHhwoWhUqlMkYuIiIjIYulcoP3222/Yvn07qlevboo8RERERBZP53PQ3NzceGNaIiIiIhPSuUAbP348Ro8ejdTUVFPkISIiIrJ4Oh/i/P777xEXFwdPT0/4+fkhX758WutPnz5ttHBERERElkjnAq1169YmiEFERERE2XQu0MaMGWOKHERERET0P7xRLREREZGZydMMWoECBXDt2jUULFgQbm5u77z3WWJiotHCEREREVmiPBVoM2bMgJOTEwBg5syZpsxDREREZPH4sHSZ4MPSiYiILIfOFwm8KS0tDS9fvtRa5uzsbFAgIiIiIkun80UCKSkp+PLLL+Hh4QEHBwe4ublpfRERERGRYXQu0IYNG4Y9e/Zg/vz5sLW1xeLFixEZGQlvb2/8/PPPpshIREREZFF0PsS5detW/Pzzz6hTpw7Cw8NRs2ZNlChRAr6+vli5ciU6d+5sipxEREREFkPnGbTExEQEBAQAeH2+WfZtNWrUqIEDBw4YNx0RERGRBdK5QAsICEB8fDwAoFSpUoiKigLwembN1dXVqOGIiIiILJHOBVp4eDjOnj0LABgxYgR++OEH2NnZYeDAgRg6dKjRAxIRERFZGoPvg3br1i2cOnUKJUqUQLly5YyVy+R4HzQiIiIyVwbdBw0AfH194evra4wsRERERAQdCrQXL14gOjoazZs3BwBEREQgPT1ds97Kygrjx4+HnZ2d8VMSERERWZA8F2g//fQTtm/frinQ5s6di5CQENjb2wMArly5Am9vbwwcONA0SYmIiIgsRJ4vEli5ciV69eqltWzVqlXYu3cv9u7di++++05zRScRERER6S/PBdr169dRtmxZzWs7Ozuo1f//7VWqVMGlS5d0+uEHDhxAixYt4O3tDZVKhV9//VVrfVhYGFQqldZXkyZNdPoZRERERHKT50OcT58+1Trn7OHDh1rrs7KytNbnRUpKCsqXL4/u3bujbdu2uW7TpEkTLFu2TPPa1tZWp59BREREJDd5LtCKFCmCCxcuICgoKNf1586dQ5EiRXT64U2bNkXTpk3fuY2trS28vLx0el8iIiIiOcvzIc5mzZph9OjRSEtLy7HuxYsXiIyMxMcff2zUcACwb98+eHh4ICgoCH379sXjx4/fuX16ejqePXum9aXrzB4RERGRlPJcoH3zzTdITExEUFAQvvvuO2zevBmbN2/GtGnTEBQUhCdPnuCbb74xargmTZrg559/RnR0NKZOnYr9+/ejadOmyMzMfOv3TJ48GS4uLlpfkydPNmouIiIiIlPS6UkC8fHx6Nu3L3bt2oXsb1OpVGjYsCHmzZuneYi6XkFUKmzatAmtW7d+6zY3btxA8eLFsXv3btSvXz/XbdLT03PMmNna2uY4d41PEiAiIiJzpdOTBPz9/bFz504kJibi+vXrAIASJUqgQIECJgn3TwEBAShYsCCuX7/+1gItt2KMiIiISE70etRTgQIFUKVKFWNn+Ve3b9/G48ePUbhw4ff+s4mIiIjelzydg9anTx/cvn07T2+4du1arFy5Mk/bJicnIyYmBjExMQBeH0KNiYlBQkICkpOTMXToUBw9ehQ3b95EdHQ0WrVqhRIlSqBx48Z5en8iIiIiOcrTDFqhQoUQEhKC6tWro0WLFggNDYW3tzfs7Ozw5MkTXLp0CQcPHsSaNWvg7e2NhQsX5umHnzx5EnXr1tW8HjRoEACgW7dumD9/Ps6dO4effvoJT58+hbe3Nxo1aoTx48fzECYREREpWp4vErh//z4WL16MNWvW5HhigJOTExo0aICePXvK5k7/vEiAiIiIzJVOV3Fme/LkCRISEvDixQsULFgQxYsXh0qlMkU+k2GBRkREROZKr4sE3Nzc4ObmZuwsRERERAQdblRLRERERO8HCzQiIiIiM8MCjYiIiMjMsEAjIiIiMjN6FWgZGRnYvXs3fvzxRzx//hwA8PfffyM5Odmo4YiIiIgskc5Xcd66dQtNmjRBQkIC0tPT0bBhQzg5OWHq1KlIT0/HggULTJGTiIiIyGLoPIP29ddfIzQ0FE+ePIG9vb1meZs2bRAdHW3UcERERESWSOcZtD///BOHDx+GjY2N1nI/Pz/cuXPHaMGIiIiILJXOM2hZWVnIzMzMsfz27dtwcnIySigiIiIiS6ZzgdaoUSPMnDlT81qlUiE5ORljxoxBs2bNjJmNiIiIyCLpfIjz+++/R+PGjVG6dGmkpaWhU6dOiI2NRcGCBbF69WpTZCQiIiKyKDoXaEWKFMHZs2exdu1anD17FsnJyejRowc6d+6sddEAEREREelHJYQQUoeQwrBFcVJH0Mm0z4tLHYGIiIjeE53PQZs8eTKWLl2aY/nSpUsxdepUo4QiIiIismQ6F2g//vgjSpUqlWN5SEgIb1JLREREZAQ6F2j37t1D4cKFcywvVKgQ7t69a5RQRERERJZM5wKtaNGiOHToUI7lhw4dgre3t1FCEREREVkyna/i/PzzzzFgwAC8evUK9erVAwBER0dj2LBhGDx4sNEDEhEREVkanQu0oUOH4vHjx/jiiy/w8uVLAICdnR2GDx+OiIgIowckIiIisjR632YjOTkZly9fhr29PQIDA2Fra2vsbCbF22wQERGRudJ5Bi2bo6MjPvjgA2NmISIiIiLoUaClpKRgypQpiI6OxoMHD5CVlaW1/saNG0YLR0RERGSJdC7Qevbsif3796NLly4oXLgwVCqVKXIRERERWSydC7TffvsN27dvR/Xq1U2Rh4iIiMji6XwfNDc3NxQoUMAUWYiIiIgIehRo48ePx+jRo5GammqKPEREREQWT+dDnN9//z3i4uLg6ekJPz8/5MuXT2v96dOnjRaOiIiIyBLpXKC1bt3aBDGIiIiIKJvOBdqYMWNMkYOIiIiI/kfnc9CIiIiIyLR0nkHLzMzEjBkzEBUVhYSEBM3zOLMlJiYaLRwRERGRJdJ5Bi0yMhLTp0/Hp59+iqSkJAwaNAht27aFWq3G2LFjTRCRiIiIyLLoXKCtXLkSixYtwuDBg2FtbY2OHTti8eLFGD16NI4ePWqKjEREREQWRecC7d69eyhbtiyA1w9MT0pKAgA0b94c27dvN246IiIiIgukc4FWpEgR3L17FwBQvHhx/PHHHwCAEydOwNbW1rjpiIiIiCyQzgVamzZtEB0dDQD46quvMGrUKAQGBqJr167o3r270QMSERERWRqVEEIY8gZHjx7F4cOHERgYiBYtWhgrl8kNWxQndQSdTPu8uNQRiIiI6D3R+TYbBw4cwEcffQRr69ffWrVqVVStWhUZGRk4cOAAatWqZfSQRERERJZE50OcdevWzfVeZ0lJSahbt65RQhERERFZMp0LNCEEVCpVjuWPHz+Gg4ODUUIRERERWbI8H+Js27YtAEClUiEsLEzris3MzEycO3cOH330kfETEhEREVmYPBdoLi4uAF7PoDk5OcHe3l6zzsbGBlWrVsXnn39u/IREREREFibPBdqyZcuQfcHnnDlz4OjoaLJQRERERJZMp3PQhBBYuXKl5ka1RERERGR8OhVoarUagYGBePz4sanyEBEREVk8na/inDJlCoYOHYoLFy6YIg8RERGRxdO5QOvatSuOHz+O8uXLw97eHgUKFND60sWBAwfQokULeHt7Q6VS4ddff9VaL4TA6NGjUbhwYdjb26NBgwaIjY3VNTIRERGRrOj8JIGZM2ca7YenpKSgfPny6N69u+Y2Hm+aNm0aZs+ejZ9++gn+/v4YNWoUGjdujEuXLsHOzs5oOYiIiIjMicHP4jQWlUqFTZs2oXXr1gBez555e3tj8ODBGDJkCIDXTyvw9PTE8uXL0aFDB4N+Hp/FSUREROZK5xk04PWNaX/99VdcvnwZABASEoKWLVvCysrKaMHi4+Nx7949NGjQQLPMxcUFH374IY4cOfLWAi09PR3p6elay2xtbbVurEtERERkznQu0K5fv45mzZrhzp07CAoKAgBMnjwZRYsWxfbt21G8uHFmeu7duwcA8PT01Fru6empWZebyZMnIzIyUmvZmDFjMHbsWKPkkgPODhIREcmbzhcJ9O/fH8WLF8dff/2F06dP4/Tp00hISIC/vz/69+9viow6iYiIQFJSktZXRESE1LGIiIiI8kznGbT9+/fj6NGjWldsuru7Y8qUKahevbrRgnl5eQEA7t+/j8KFC2uW379/HxUqVHjr9/FwJhEREcmdzjNotra2eP78eY7lycnJsLGxMUooAPD394eXlxeio6M1y549e4Zjx46hWrVqRvs5REREROZG5wKtefPm6NWrF44dOwYhBIQQOHr0KPr06YOWLVvq9F7JycmIiYlBTEwMgNcXBsTExCAhIQEqlQoDBgzAhAkTsGXLFpw/fx5du3aFt7e35kpPIiIiIiXS+RDn7Nmz0a1bN1SrVg358uUDAGRkZKBly5aYNWuWTu918uRJ1K1bV/N60KBBAIBu3bph+fLlGDZsGFJSUtCrVy88ffoUNWrUwM6dO3kPNCIiIlI0ve+DFhsbi8uXL0OlUiE4OBglSpQwdjaTUvKVjkpuGxERkSXQ6z5oABAYGKgpylQqldECEREREVk6nc9BA4AlS5agTJkysLOzg52dHcqUKYPFixcbOxsRERGRRdJ5Bm306NGYPn06vvrqK83VlEeOHMHAgQORkJCAcePGGT0kERERkSXRuUCbP38+Fi1ahI4dO2qWtWzZEuXKlcNXX33FAo2IiIjIQDof4nz16hVCQ0NzLK9cuTIyMjKMEoqIiIjIkulcoHXp0gXz58/PsXzhwoXo3LmzUUIRERERWTK9ruJcsmQJ/vjjD1StWhUAcOzYMSQkJKBr166ae5kBwPTp042TkoiIiMiC6FygXbhwAZUqVQIAxMW9vt9WwYIFUbBgQVy4cEGzHW+9QURERKQfnQu0vXv3miIHEREREf2PXvdBIyIiIiLT0XkGLS0tDXPmzMHevXvx4MEDZGVlaa0/ffq00cIRERERWSKdC7QePXrgjz/+wCeffIIqVarwXDMiIiIiI9O5QNu2bRt27NiB6tWrmyIPERERkcXT+Rw0Hx8fODk5mSILEREREUGPAu3777/H8OHDcevWLVPkISIiIrJ4Oh/iDA0NRVpaGgICApA/f37ky5dPa31iYqLRwhERERFZIp0LtI4dO+LOnTuYNGkSPD09eZEAERERkZHpXKAdPnwYR44cQfny5U2Rh4iIiMji6XwOWqlSpfDixQtTZCEiIiIi6FGgTZkyBYMHD8a+ffvw+PFjPHv2TOuLiIiIiAyj8yHOJk2aAADq16+vtVwIAZVKhczMTOMkIyIiIrJQfFg6ERERkZnRuUCrXbu2KXIQERER0f/kuUA7d+5cnrYrV66c3mGIiIiISIcCrUKFClCpVBBCvHUbnoNGREREZLg8F2jx8fGmzEFERERE/5PnAs3X19eUOYiIiIjof3S+DxoRERERmRYLNCIiIiIzo/NtNoikNGxRnNQRdDLt8+JSRyAiIhniDBoRERGRmdGrQMvIyMDu3bvx448/4vnz5wCAv//+G8nJyUYNR0RERGSJdD7EeevWLTRp0gQJCQlIT09Hw4YN4eTkhKlTpyI9PR0LFiwwRU4iIiIii6HzDNrXX3+N0NBQPHnyBPb29prlbdq0QXR0tFHDEREREVkinWfQ/vzzTxw+fBg2NjZay/38/HDnzh2jBSMiIiKyVDrPoGVlZeX6OKfbt2/DycnJKKGIiIiILJnOM2iNGjXCzJkzsXDhQgCvn7+ZnJyMMWPGoFmzZkYPSGQpeAsRIiLKpnOB9v3336Nx48YoXbo00tLS0KlTJ8TGxqJgwYJYvXq1KTISERERWRSdC7QiRYrg7NmzWLNmDc6dO4fk5GT06NEDnTt31rpogIiIiIj0o3OBlpaWBjs7O3z22WemyENERERk8XS+SMDDwwPdunXDrl27kJWVZYpMRERERBZN5wLtp59+QmpqKlq1agUfHx8MGDAAJ0+eNEU2IiIiIoukc4HWpk0brFu3Dvfv38ekSZNw6dIlVK1aFSVLlsS4ceNMkZGIiIjIouj9sHQnJyeEh4fjjz/+wLlz5+Dg4IDIyEhjZiMiIiKySHoXaGlpaYiKikLr1q1RqVIlJCYmYujQocbMRkRERGSRdL6K8/fff8eqVavw66+/wtraGp988gn++OMP1KpVyxT5iEgBeBNeIiLd6FygtWnTBs2bN8fPP/+MZs2aIV++fKbIRURERGSxdD7Eef/+fURFRaFVq1YmL87Gjh0LlUql9VWqVCmT/kwiIiIiqeVpBu3Zs2dwdnYGAAgh8OzZs7dum72dsYSEhGD37t2a19bWOk/6ERGZDA/fEpEp5KnacXNzw927d+Hh4QFXV1eoVKoc2wghoFKpkJmZadyA1tbw8vIy6nsSERERmbM8FWh79uxBgQIFAAB79+41aaB/io2Nhbe3N+zs7FCtWjVMnjwZxYoVe68ZiIgsEWcHiaSTpwKtdu3amn/7+/ujaNGiOWbRhBD466+/jBruww8/xPLlyxEUFIS7d+8iMjISNWvWxIULF+Dk5JTr96SnpyM9PV1rma2tLWxtbY2ajYiIiMhUdL5IwN/fHw8fPsyxPDExEf7+/kYJla1p06Zo164dypUrh8aNG2PHjh14+vQpoqKi3vo9kydPhouLi9bX5MmTjZqLiIiIyJR0PuM++1yzf0pOToadnZ1RQr2Nq6srSpYsievXr791m4iICAwaNEhrGWfPiIjoTTx8S+YuzwVadtGjUqkwatQo5M+fX7MuMzMTx44dQ4UKFYwe8E3JycmIi4tDly5d3roND2cSERGR3OW5QDtz5gyA1zNo58+fh42NjWadjY0NypcvjyFDhhg13JAhQ9CiRQv4+vri77//xpgxY2BlZYWOHTsa9ecQERERmZM8F2jZV2+Gh4dj1qxZRr/fWW5u376Njh074vHjxyhUqBBq1KiBo0ePolChQib/2URERERS0fkctGXLlpkiR67WrFnz3n4WERERkbnQ67b8J0+eRFRUFBISEvDy5UutdRs3bjRKMCIiIiJLpXOBtmbNGnTt2hWNGzfGH3/8gUaNGuHatWu4f/8+2rRpY4qMRERElEe8QlUZdL4P2qRJkzBjxgxs3boVNjY2mDVrFq5cuYL27dvzDv9ERERERqDzDFpcXBw+/vhjAK+v3kxJSYFKpcLAgQNRr149REZGGj0kERERkSXNDuo8g+bm5obnz58DAHx8fHDhwgUAwNOnT5Gamqp3ECIiIiJ6TecZtFq1amHXrl0oW7Ys2rVrh6+//hp79uzBrl27UL9+fVNkJCIiIrIoOhdoc+fORVpaGgBg5MiRyJcvHw4fPoz//Oc/+Pbbb40ekIiIiMjS6FygFShQQPNvtVqNESNGGDUQERERkaXLU4H27NmzPL/h+3jCABEREZGS5alAc3V1hUqleuc2QgioVCpkZmYaJRgRERGRpcpTgZb9HE4iIiIiMr08FWi1a9c2dQ4iIiIi+h+d74MGAH/++Sc+++wzfPTRR7hz5w4AYMWKFTh48KBRwxERERFZIp0LtA0bNqBx48awt7fH6dOnkZ6eDgBISkrCpEmTjB6QiIiIyNLoXKBNmDABCxYswKJFi5AvXz7N8urVq+P06dNGDUdERERkiXQu0K5evYpatWrlWO7i4oKnT58aIxMRERGRRdO5QPPy8sL169dzLD948CACAgKMEoqIiIjIkulcoH3++ef4+uuvcezYMahUKvz9999YuXIlhgwZgr59+5oiIxEREZFF0flRTyNGjEBWVhbq16+P1NRU1KpVC7a2thgyZAi++uorU2QkIiIisig6F2gqlQojR47E0KFDcf36dSQnJ6N06dJwdHTEixcvYG9vb4qcRERERBZDr/ugAYCNjQ1Kly6NKlWqIF++fJg+fTr8/f2NmY2IiIjIIuW5QEtPT0dERARCQ0Px0Ucf4ddffwUALFu2DP7+/pgxYwYGDhxoqpxEREREFiPPhzhHjx6NH3/8EQ0aNMDhw4fRrl07hIeH4+jRo5g+fTratWsHKysrU2YlIiIisgh5LtDWrVuHn3/+GS1btsSFCxdQrlw5ZGRk4OzZs1CpVKbMSERERGRR8nyI8/bt26hcuTIAoEyZMrC1tcXAgQNZnBEREREZWZ4LtMzMTNjY2GheW1tbw9HR0SShiIiIiCxZng9xCiEQFhYGW1tbAEBaWhr69OkDBwcHre02btxo3IREREREFibPBVq3bt20Xn/22WdGD0NEREREOhRoy5YtM2UOIiIiIvofvW9US0RERESmwQKNiIiIyMywQCMiIiIyMyzQiIiIiMwMCzQiIiIiM8MCjYiIiMjMsEAjIiIiMjMs0IiIiIjMDAs0IiIiIjPDAo2IiIjIzLBAIyIiIjIzLNCIiIiIzAwLNCIiIiIzwwKNiIiIyMywQCMiIiIyMyzQiIiIiMwMCzQiIiIiM8MCjYiIiMjMsEAjIiIiMjOyKNB++OEH+Pn5wc7ODh9++CGOHz8udSQiIiIikzH7Am3t2rUYNGgQxowZg9OnT6N8+fJo3LgxHjx4IHU0IiIiIpMw+wJt+vTp+PzzzxEeHo7SpUtjwYIFyJ8/P5YuXSp1NCIiIiKTMOsC7eXLlzh16hQaNGigWaZWq9GgQQMcOXJEwmREREREpmMtdYB3efToETIzM+Hp6am13NPTE1euXMn1e9LT05Genq61zNbWFra2tibLSURERGRUwozduXNHABCHDx/WWj506FBRpUqVXL9nzJgxAoDW15gxY95DWiHS0tLEmDFjRFpa2nv5ee8T2yZPbJs8sW3yxLbJk7m2TSWEEJJWiO/w8uVL5M+fH+vXr0fr1q01y7t164anT59i8+bNOb5Hyhm0Z8+ewcXFBUlJSXB2djb5z3uf2DZ5YtvkiW2TJ7ZNnsy1bWZ9DpqNjQ0qV66M6OhozbKsrCxER0ejWrVquX6Pra0tnJ2dtb54eJOIiIjkxKzPQQOAQYMGoVu3bggNDUWVKlUwc+ZMpKSkIDw8XOpoRERERCZh9gXap59+iocPH2L06NG4d+8eKlSogJ07d+a4cICIiIhIKcy+QAOAL7/8El9++aXUMf6Vra0txowZo8hDqmybPLFt8sS2yRPbJk/m2jazvkiAiIiIyBKZ9UUCRERERJaIBRoRERGRmWGBRkRERGRmWKARERERmRlZXMVpzhISEnDr1i2kpqaiUKFCCAkJMbsrQXSVlZWF/fv3488//9RqW8WKFdGgQQMULVpU6ogGU+Lf7Z/S09MV16ZXr17h3r17mr9bgQIFpI5ksKdPn2LTpk259rfGjRvjo48+kjqiwZT4d/snpfW3+Pj4XD+T1apVg52dndTxDCKbtkn7pCl5io+PF8OGDRPFihUTarVaqFQqzZetra1o0KCBiIqKEpmZmVJH1UlqaqoYP3688Pb2FnZ2dqJq1aqibdu2onPnzqJp06aiaNGiwsrKSjRt2lQcOXJE6rg6U+rfLduOHTtE165dhb+/v7C2thZqtVo4OTmJWrVqiQkTJog7d+5IHVEvz549E/PmzRO1atUSdnZ2mr+dWq0WxYoVEz179hTHjx+XOqbO7ty5I3r06CHs7OxEQECA6NChgxg0aJAYOXKk6Nu3r6hZs6bInz+/CA4OFmvWrJE6rs6U+nfLptT+9ssvv4gPPvhAqFQq4eXlJSpVqiSqV68ugoODhY2NjXB2dhZ9+/YVN2/elDqqzuTWNhZoOvrqq6+Es7OzaNeunfj555/FlStXxLNnz8SrV6/E/fv3RXR0tBg7dqwoVaqUCAkJkdV/QEWKFBHt2rUT27dvFy9fvsx1m5s3b4pJkyYJX19fsXDhwvecUH9K/rtt3LhRBAYGCi8vL9G9e3exYMECsWXLFrFr1y6xdu1aMWrUKFGnTh1ha2srevfuLR48eCB15Dz7/vvvRYECBcQHH3wgxo0bJ3bu3CnOnTsnYmNjxbFjx8SSJUtEWFiYcHV1FY0bNxbXrl2TOnKeeXh4iKFDh4qLFy++dZvU1FSxatUqUbVqVfHdd9+9x3SGUfLfTcn9rUKFCqJKlSrihx9+EAkJCTnWp6Wlib1794revXuLggULiqioKAlS6keObWOBpqMRI0aIR48e5Wnb3377TWzYsMHEiYzn0qVLed725cuX4vr16yZMY1xK/rtVrVpVbNu27V9n/m7fvi2GDx8upk+f/p6SGa5Dhw7iwoUL/7pdWlqamD9/vliyZMl7SGUcef086ru9lJT8d1Nyf9u5c2eet3306JE4efKkCdMYlxzbxhvVEhEREZkZXsWppxcvXuDvv/+WOoZJrFixApMmTcL169eljmJy6enpiIuLQ3p6utRRTCI+Ph4ZGRlSxzCKrKwsqSMYXXp6Ol69eqV5HRcXh5EjR6JLly749ttvER8fL2E60pVS+tuff/6JVatW4cmTJ1JHMTo5tY0Fmh52794NDw8PFC1aFE2bNkVycrLUkYwmIiICvXv3xtq1a1G5cmUcPHhQ6khGs3z5chw5cgQAkJaWhh49esDBwQElS5aEo6Mj+vTpo7hCLSgoCLGxsVLHMMiZM2dQvHhxODo6om/fvsjMzJQ6ktE0btwYmzdvBgAcOnQIISEh2LZtG169eoUdO3agTJkyms+sHJ09exYTJkzAvHnz8OjRI611z549Q/fu3SVKZhpK6G8zZ85EnTp10K9fP5QtWxZXrlyROpLRyK1tPMSphwoVKqBatWro1asXRowYgdTUVGzfvh3Ozs5SRzNY4cKFsWDBArRq1QrLli3DwIED8d///hclS5ZE5cqVcfnyZaSmpqJWrVpSR9VZQEAAVq9ejQ8//BBDhw7F+vXrMX36dAQHB+Pq1asYNmwYWrVqhWnTpkkdVWdt27bNdfnmzZtRr149ODk5AQA2btz4PmMZRfXq1eHh4YGuXbti3LhxKFGiBFavXg1ra/nfJcjFxQUnT55EYGAg6tSpg0qVKmH69Oma9aNGjcLevXtluaP0xx9/oEWLFggMDMTz58+RkpKCdevWoW7dugCA+/fvw9vbW5YFt5L7m5+fH0aNGoUePXpgzJgxWLRoEX7++WeULFkS3t7eePjwIV69eoVixYpJHVVnsmubtKfAyVP+/PnFjRs3hBBCpKeni0aNGglHR0fh7+8vLly4IOrXry/8/f0lTqkfZ2dnERcXp3m9fPly4ezsLNRqtTh16pQoVaqUUKvVEibUn62trbh165YQQoiSJUuK3377TWv9/v37RbFixaSIZjCVSiVq164twsLCtL7UarVo3bq15rUcOTg4aK7ye/LkiahYsaLw8/MTdevWFdeuXRNdu3YVdevWlTilfhwcHMTly5eFEEJ4enqKmJgYrfXXr18Xjo6OUkQzWLVq1cQ333wjhBAiKytLTJ06VTg6Omr63b1792T7f4nS+1t8fLzmdWRkpFCr1YoYA+TWNhZoeihRooQ4ePCg5nVGRoaIiooSs2bNEg8ePBBz584VY8eOlTCh/mrUqCFWrVqltSwzM1MkJSWJzMxMcefOHbO5R4yufH19xZ49e4QQQvj4+IgTJ05orb906ZJwcHCQIprBVq9eLYoUKSKWLl2qtdza2vqdt3GQA19fX62/1bNnz8S0adPEwIEDxV9//SUiIiJkOxjWq1dPTJs2TQghxEcffSR++uknrfXr16+X7U6Ds7Nzjiu9V65cKRwcHMTWrVtlXaApub9VrlxZbNmyRWvZ/fv3xdmzZ8WLFy/E8ePHxb59+yRKZxi5tY0Fmh4iIiJEly5dpI5hEps3bxZffvml1DFM4ptvvhHVqlUTT548ESNGjBAtWrQQz58/F0IIkZKSItq3by8aNWokcUr9xcfHi+rVq4u2bduKxMREIYQyBox+/fqJ/v37Sx3DJA4fPixcXFzEmDFjxJw5c0TBggXFt99+K1auXClGjx4tXF1dxdSpU6WOqZdChQrlequC1atXi/z584v58+fLtkATQrn9bcmSJeKzzz6TOoZJyK1tLND0kJaWluuN7si8paeni5YtWwo3NzfRsGFDYWdnJ/Lnzy8CAwOFg4ODKFasmLh69arUMQ2SmZkpRo8eLYoWLSp27twp8uXLJ/sB4/Hjx7J8ckVeHT58WFStWlXryRYqlUr4+PiImTNnSh1Pbw0bNnzrzXVXrVol8uXLJ+sCTQhl9jcyH7xIwEgOHTqE0NBQRT2LLdsXX3yBcePGoWDBglJHMYqdO3di69atuHHjBrKyslC4cGFUr14dnTp1goODg9TxjOLgwYPo2rUrbt26hfPnz6N06dJSRzKq27dvw9vbG2q1ci5Ef/jwodZn0s/PT+pIBtm0aRMOHDiAGTNm5Lp+1apVWLRoEfbu3fuekxmf0vvblClT0KdPH7i6ukodxejMuW0s0IzE2dkZMTExCAgIkDqK0Sm5bUqWnJyMuLg4BAcHw8bGRuo4RqXkz6QSi09LwP4mT+bcNv4PYCRKrnOV3LYvvvgix/2ZlGLu3Lnw9fVV3GABKPszWbp0ady8eVPqGCbB/iZPSu5v5tw2Fmhk0X755Rc8e/ZM6hgmMWnSJCQmJkodg3RkzgOGodjfiPJO/nd6NBM//vgjPD09pY5hEs+fP5c6gskoeTBUctu++eYbFChQQOoYpCMlfyaV3LZLly7B29tb6hgmYc5tY4FmJJ06dZI6ApHFiIiIkDqCybD4JHNTtGhRqSOYjDm3jYc4TSAuLg716tWTOoZeXr16hWHDhqFEiRKoUqUKli5dqrX+/v37sLKykiid8T1//twsTw41hkuXLsHX11fqGEZx9+5d/PLLL9ixYwdevnyptS4lJQXjxo2TKJnxRUREmOUVZcbA/iZ/Z8+eVdQY8CZzaxsLNBNITk7G/v37pY6hl4kTJ+Lnn39Gnz590KhRIwwaNAi9e/fW2kapU/kZGRlISEiQOobRFC1a1Kz+s9HXiRMnULp0afTr1w+ffPIJQkJCcPHiRc365ORkREZGSpjQMJZUfL6J/U2+lDoGAObVNt5mQw+zZ89+5/o7d+7gv//9rywfAhwYGIgZM2agefPmAIDr16+jadOmqFGjBpYuXYoHDx7I9gHH/+bs2bOoVKkS22ZmGjZsiKJFi2Lx4sVISUnB8OHDERUVhV27dqFixYqyfuj2iRMn0KhRI2RlZeHVq1fw8fHBr7/+ipCQEADyfqD4v5HzZ/LfyLltb3sQfLakpCTs27ePbXsPeA6aHgYMGIDChQu/9XLqf+4Fy8mdO3dQpkwZzesSJUpg3759qFevHrp06YJp06ZJmI4MIdd9sVOnTuGHH36AWq2Gk5MT5s2bh2LFiqF+/fr4/fffUaxYMakj6u2bb75BmzZttIrP2rVra4pPki+59retW7eiYcOGb73ozVyKF33IrW0s0PTg6+uLqVOnon379rmuj4mJQeXKld9zKuPw8vJCXFyc1l3MfXx8sHfvXtStWxdhYWGSZTNUpUqV3rn+xYsX7ymJ8eVlz1ClUr2nNMaXlpam9XrEiBGwtrZGo0aNcpwnKSdKLj7Z3+TZ34KDg/Gf//wHPXr0yHV9TEwMtm3b9p5TGYfc2sYCTQ+VK1fGqVOn3lqgqVQq2e491atXD6tWrUL9+vW1lnt7e2PPnj2oU6eONMGM4NKlS+jQoQP8/f1zXX/37l1cu3btPacyDrntGeqiTJkyOHz4MMqVK6e1fMiQIcjKykLHjh0lSmYcSi0+2d/kqXLlyjh9+vRbixhbW1vZ7jjIrm3v88GfSnHx4kVx4sSJt65/+fKluHnz5ntMZDw3b94UO3fufOv6O3fuiOXLl7/HRMZTuXJlMW/evLeuP3PmjGwf3ly2bFmxePHit66Xc9sWLVokPvvss7eunzJlivDz83uPiYynZs2aYv78+bmumzp1qrC1tZXt3439TZ5tS0tLEykpKVLHMAm5tY1XceqhdOnSCA0Nfev6fPnyyfZya19fXzRu3Pit6729vdGtW7f3mMh4qlevjqtXr751vZOTE2rVqvUeExlP9p7h25jdnqEOevbsiRUrVrx1/fDhwxEfH/8eExlP165dcejQoVzXDRs2DJGRkbL9u7G/yfPvZmtri/z580sdwyTk1jZexUnvdOnSJSQkJOS48KFly5YSJaLcpKenIzMzU1b/+RDJlaX1t7S0tBxjgLOzs0RpjCMzMxObNm3C5cuXAbw+P61169awtjafM79YoBlo/fr1iIqKyrWIedcelrm7ceMG2rRpg/Pnz2udU5d94qucz7Eg+VJqfyMyN6mpqRg2bBiioqLw+PHjHOvlPAZcvHgRLVu2xL179xAUFAQAuHbtGgoVKoStW7dq3clASjzEaYDZs2cjPDwcnp6eOHPmDKpUqQJ3d3fcuHEDTZs2lTqeQb7++mv4+/vjwYMHyJ8/Py5evIgDBw4gNDQU+/btkzqeUaSmpuLKlSs4d+6c1pfcZWZmYv369Rg/fjzGjx+P9evXIyMjQ+pYBlNyfwNeF5/t27dH1apVUalSJa0vJVBqf8uWlpaGZ8+eaX3J2dChQ7Fnzx7Mnz8ftra2WLx4MSIjI+Ht7Y2ff/5Z6ngG6dmzJ0JCQnD79m2cPn0ap0+fxl9//YVy5cqhV69eUsf7f5KeASdzQUFBYtWqVUIIIRwdHUVcXJwQQohRo0aJfv36SRnNYO7u7uLs2bNCCCGcnZ3FlStXhBBCREdHiwoVKkgZzWAPHjwQH3/8sVCr1bl+ydmFCxdEQECAyJ8/v6hYsaKoWLGicHBwEH5+fuL8+fNSxzOIkvvbrFmzhKOjo/jyyy+FjY2N6N27t2jQoIFwcXER33zzjdTxDKLk/paSkiL69esnChUqpLi2FS1aVOzdu1cIIYSTk5OIjY0VQgjx888/i6ZNm0qYzHB2dnbiwoULOZafP39e2NnZSZAod5xBM0BCQgI++ugjAIC9vT2eP38OAOjSpQtWr14tZTSDZWZmwsnJCQBQsGBB/P333wBeX0TwrhN/5WDAgAF4+vQpjh07Bnt7e+zcuRM//fQTAgMDsWXLFqnjGUQ2e4Z6UHJ/mzdvHhYuXIg5c+bAxsYGw4YNw65du9C/f38kJSVJHc8gSu5vSp5lSkxM1Dw31dnZGYmJiQCAGjVq4MCBA1JGM1jJkiVx//79HMsfPHiAEiVKSJDoLaSuEOXM399fnD59Wgjx+pLyBQsWCCGE+P3334Wbm5uU0QxWo0YNsWnTJiGEEB07dhRNmjQRBw8eFF27dhUhISHShjOQl5eXOHbsmBDi9Z7h1atXhRBCbN68WVSvXl3KaAaTy56hPpTc3+zt7TW35ilUqJCIiYkRQghx7do1UaBAASmjGUzJ/U3Js0xly5YV+/btE0IIUb9+fTF48GAhxOvZXh8fHymj6SUpKUnztX37dhESEiLWrVsn/vrrL/HXX3+JdevWibJly4rt27dLHVXDfC5XkKF69ephy5YtqFixIsLDwzFw4ECsX78eJ0+e/Nc7TZu7b7/9FikpKQCAcePGoXnz5qhZsybc3d2xdu1aidMZJiUlBR4eHgAANzc3PHz4ECVLlkTZsmVlf6J59p5h9rMcs5ndnqEelNzfvLy8kJiYCF9fXxQrVgxHjx5F+fLlER8fL9ubXmdTcn971yxT3759pYxmsPDwcJw9exa1a9fGiBEj0KJFC8ydOxevXr3C9OnTpY6nM1dXV62nOwgh0L59e82y7H7WokULs7kAggWaARYuXIisrCwAQL9+/eDu7o7Dhw+jZcuW6N27t8TpDPPmvdBKlCiBK1euIDExEW5ubrJ9hEm2oKAgXL16FX5+fihfvjx+/PFH+Pn5YcGCBShcuLDU8XT25snIkydPRv/+/TF27FhUrVoVAHD06FGMGzcOU6dOlSqiUSi5vym5+FRaf3tTQEAA4uPjUaxYMZQqVQpRUVGoUqUKtm7dCldXV6njGWTgwIGafzdo0ABXrlzBqVOnUKJEiRxP9ZCDvXv3Sh1BZ7zNBlmcX375BRkZGQgLC8OpU6fQpEkTJCYmwsbGBsuXL8enn34qdUSdqNXqHHuGAHLsGapUKrPZMyRtWVlZyMrK0tyDac2aNTh8+DACAwPRu3dv2NjYSJxQf0rrb2+aMWMGrKys0L9/f+zevRstWrSAEEIzy/T1119LHZFkjAWajhISEnS6Q/SdO3fg4+NjwkTG06dPH3z77bcoUqTIv267du1aZGRkoHPnzu8hmWllX/5frFgxFCxYUOo4Otu/f3+et61du7YJkxifkvubpZJ7f3uXW7duyXqWac2aNejQoUOetv3rr7+QkJCA6tWrmziVccjy/xKpTn6TKw8PD9GrVy9x/Pjxt27z9OlTsXDhQhESEiJmzZr1HtMZ5ttvvxXOzs6iadOmYt68eeL48ePi9u3b4tGjRyI2NlZs3rxZDB06VBQtWlR8+OGHmttwEJmKkvvbrVu3dNr+9u3bJkpC9FqtWrVEqVKlxNSpU8WlS5dyrH/69KnYvn276NixoyhYsKDYvHmzBCn1I8f/S1ig6ejRo0di4MCBwsXFRXh6eopmzZqJnj17ii+//FJ07txZVKxYUdjY2IiqVaua1dUgeXXv3j0xYcIEUaZMmRz39HFxcRH/+c9/xG+//SZ1TJ1NnjxZpKam5mnbo0ePim3btpk4kfEoeaBXcn+T44CRV0rub6tXr87ztgkJCeLgwYMmTGN8mzdvFg0aNBBqtVo4OTmJEiVKiDJlyggfHx9hZWUlPD09xfDhw8W9e/ekjqoTOf5fwkOcenrx4gW2b9+OgwcP4tatW3jx4gUKFiyIihUronHjxmbzqAhDPHnyBAkJCZq2FS9eXLYXCHTt2hW//fYb2rVrhxYtWiA0NBSFChUCAGRkZODSpUs4ePAgfvnlF/z999/4+eefZfMgZ09PT7Ru3Ro9e/bEBx98kOs2SUlJiIqKwqxZs9CrVy/079//Pac0jBL72+PHjzFx4kQsXboUdnZ2qFy5Mry9vWFnZ4cnT57g0qVLuHjxIipVqoRRo0ahWbNmUkfOMyX3t9q1a+PBgwcIDw9HixYtEBwcrLU+KSkJhw4dwi+//IJdu3ZhyZIlsnx28aNHj3LtbxUrVoRaLd9bqMrp/xIWaGQxzp49i7lz52L9+vV49uwZrKysYGtri9TUVABAxYoV0bNnT4SFhcHOzk7itHmn5IHeEshpwNCFUvsbAGzZsgVz5szBnj174ODgAE9PT01/u3fvHgoWLIiwsDAMHDgQnp6eUsclmWKBRrlatmwZHB0d0a5dO63l69atQ2pqKrp16yZRMsNlZWXh3LlzWoNhhQoVZH/CslIH+mxJSUnIzMxEgQIFtJYnJibC2toazs7OEiWjd1FqfwOUO8sEACdOnEBWVhY+/PBDreXHjh2DlZUVQkNDJUpmOVig6UiXexJt3LjRhElMq2TJkvjxxx9Rt25dreX79+9Hr169ZP+4J5Kfpk2bokWLFvjiiy+0li9YsABbtmzBjh07JEpmOBafZG6qVKmCYcOG4ZNPPtFavnHjRkydOhXHjh2TKJl+5Dh280a1OnJxcZE6wnuRkJAAf3//HMt9fX2RkJAgQSLj2bFjB6ysrLRuxgsAv//+O7KystC0aVOJktG7HDt2LNc7mNepUwcjR46UIJHxdOjQIdfiMyoqSvbFp5L7m5JnmS5duoRKlSrlWF6xYkVcunRJgkSGkePYzQJNR8uWLZM6wnvh4eGBc+fOwc/PT2v52bNn4e7uLk0oIxkxYgSmTJmSY7kQAiNGjJDdgCHHPUN9pKenIyMjI8fyV69e4cWLFxIkMh4lF59K629v6tevH4YNG5ajQLtz544sZ5neZGtri/v372seZZXt7t27mhsqy4kcx255HyQnk+nYsSP69++PvXv3IjMzE5mZmdizZw++/vrrPN/I0FzFxsaidOnSOZaXKlUK169flyCRYVxcXPL8JWdVqlTBwoULcyxfsGABKleuLEEi41Fy8am0/vYmpc0yvalRo0aIiIhAUlKSZtnTp0/xzTffoGHDhhImsxzyK4PNzPr16xEVFYWEhAS8fPlSa52cHwQ8fvx43Lx5E/Xr19fsLWVlZaFr166YNGmSxOkM4+Lighs3buSYHbx+/TocHBykCWUAOe4Z6mPChAlo0KABzp49i/r16wMAoqOjceLECfzxxx8SpzNMdvE5Z84creVKKD6V1t/epLRZpjf997//Ra1ateDr64uKFSsCAGJiYuDp6YkVK1ZInM5wchi7OYNmgNmzZyM8PByenp44c+YMqlSpAnd3d9y4cUPW0/YAYGNjg7Vr1+LKlStYuXIlNm7ciLi4OCxdulTWzwUEgFatWmHAgAGIi4vTLLt+/ToGDx4sy/sVWYrq1avjyJEjKFq0KKKiorB161aUKFEC586dQ82aNaWOZ5AJEyZg8eLFqFWrFiIjIxEZGYlatWph6dKlst8hUnJ/U/Isk4+PD86dO4dp06ahdOnSqFy5MmbNmoXz58+jaNGiUscziFzGbl7FaYBSpUphzJgx6NixI5ycnHD27FkEBARg9OjRSExMxNy5c6WOSLlISkpCkyZNcPLkSc1zR2/fvo2aNWti48aNcHV1lTaggeSwZ2hMWVlZ2LFjB5o3by51FIPExMTgu+++Q0xMDOzt7VGuXDlEREQgMDBQ6mgGUXJ/u3PnDmrVqoXHjx/nmGXatWuX7AuZ3Fy+fBlLlizBf//7X6mj6E0uYzcLNAPkz58fly9fhq+vLzw8PLBr1y6UL18esbGxqFq1Kh4/fix1RJ09ffoUq1evRt++fQEAnTt31joHxsrKCosWLZL1f6rA6xOUd+3ahbNnz2oGQ7ncyfxdZs+ejZEjRyIsLAwLFy5EeHg44uLicOLECfTr1w8TJ06UOqLRXL9+HUuXLsXy5cvx8OFDvHr1SupIRqeU4lOp/Q0AUlJSsHLlSq22dezYEfny5ZM6mtGkpKRgzZo1WLJkCY4ePYrSpUvjwoULUsfSm2zG7vf/dCnl8Pf3F6dPnxZCCFG5cmWxYMECIYQQv//+u3Bzc5Mymt6mTZsmOnXqpHnt6Ogo/vOf/4iwsDARFhYmgoKCxJgxY6QLSO8UFBQkVq1aJYR4/beLi4sTQggxatQo0a9fPymjGUVqaqr46aefRM2aNYVarRa1a9cW8+fPl91zAf9NbGysiIiIEIULFxbW1tZSxyEdXbp0SQwePFjqGAY7ePCgCA8PFw4ODkKtVovBgweLy5cvSx3LYHIZu+V9FqPE6tWrhy1btqBixYoIDw/HwIEDsX79epw8eVKnWx+Yk/Xr1+eYZZk2bZrmJNhNmzZh3LhxGDt2rATpjGPcuHHvXD969Oj3lMT4EhIS8NFHHwEA7O3t8fz5cwBAly5dULVqVbOZutfViRMnsHjxYqxZswbFixdH586dcfjwYcybNy/XKwTl6MWLF1i3bh0WL16MQ4cOoWbNmhg9ejTatGkjdTSDKLm/vSm3WSY5HgZ88OABli9fjqVLlyIpKQkdO3bEvn37UK1aNXTv3h2lSpWSOqLB5DJ2s0AzwMKFC5GVlQXg9f1w3N3dcfjwYbRs2RK9e/eWOJ1+bty4gaCgIM3roKAgrYsCsqeB5WzTpk1ar1+9eoX4+HhYW1ujePHish4wvLy8kJiYCF9fXxQrVgxHjx5F+fLlER8fDyHTsxnKlSuHZ8+eoVOnTjh8+DBCQkIAvL6/lhIovfhUcn8DgEOHDmHJkiWIiorCixcvMHDgQCxdulS2hYyvry8++eQTzJo1Cw0bNpT9I6tyI5exmwWaAdRqtdaHt0OHDrK/R1hKSgqSkpI0J7eePHkyx/rsD7ZcnTlzJseyZ8+eISwsTPazFXLZM9TF1atX8emnn6Ju3bqKKFjepPTiE1Bmf1PyLJOvry8OHjyIYsWKwdfXV9ZteRu5jN0s0PT07NkzzfPxduzYoXWTSSsrK3z88cdSRTNIQEAATp8+/dYHa588eTLXR0DJnbOzMyIjI9GiRQt06dJF6jh6k8ueoS5u3LiB5cuXo2/fvnjx4gU6duyIzp07Q6VSSR3NYEouPt9F7v1NybNMV65c0cwKfvDBByhZsiQ+++wzAFBEn5PV2C31SXBytHXrVlGhQgXNa0dHR6FSqTRfarVarFu3TsKE+vv2229F0aJFcz3p+u7du6Jo0aJi5MiREiQzvT///FO4urpKHYPeITo6WnTu3FnY29sLlUolhg4dKq5evSp1LL3dvn1bTJgwQRQvXlx4e3uLwYMHi9OnT4t8+fKJixcvSh3PpOTc34KCgoSfn5/45ptvtE6at7a2VtTf7fnz52LhwoWiWrVqQqVSiTp16oiFCxeKBw8eSB1NL3Ibu3mbDT20bNkSrVu3Rvfu3QFA6z4qwOuT6vft2yfLBxw/f/4cH374IW7fvo0uXbqgZMmSAF7v6f/yyy/w8fHB8ePH4eTkJHFS/c2ePVvrtRACd+/exYoVK1C7dm2sWrVKomSGkdWeoYGSkpKwcuVKLF26VDPje+7cOaljGWTPnj1YunQpNm7ciLS0NAwZMgQ9e/bU9EG5Ump/y55lWrdunWaWadiwYTh37hyCg4Oljmd02fc/W7FiBRITE2V5WxvZjd3S1ofy5OfnJ65cuaJ5/ebtDIQQ4ty5c6JQoUJSRDOKxMRE0bt3b+Hm5qbZs3BzcxO9e/cWjx8/ljqewfz8/LS+AgICxIcffigiIiLEs2fPpI6nF7ntGRrTmTNnxFdffSV1DKN5+vSp+OGHH0TlypWFSqUSZcuWlTqSQZTY396ktFmmf/Py5UuxYcMGqWPoRW5jN2fQ9GBnZ4crV65oni138uRJlC9fXnNjwvj4eJQqVQrp6ekSpjScEAIPHz4EABQqVEgR5x8olez2DClPYmJisHTp0hyzUGSelDDLpGRyG7uVc2bje1SgQAFcv35d8zo0NFTrrtGxsbEoUKCAFNGMSqVSwcPDAx4eHooozooVK6Z1h+i5c+fi2bNnEiYynvPnz6N69epvXd+0adMcV+TKxfHjx5GZmal5vW3bNtSuXRs+Pj4IDQ3Fzz//LGE606pQoYJsizMl97e3CQ4Oxn//+1/cvn0ba9eulTqOXtRqNaysrN75JdcHwctt7OYMmh46dOiA1NRUbNmyJdf1zZs3h4ODgyw76PHjx1G5cmVYWVkBeD0Yfvfdd7h+/ToKFy6M/v37o2vXrhKn1I9arca9e/fg4eEB4PWVZDExMZpZJjmT256hLqysrHD37l14eHhg69ataN26NT777DN8+OGHOHPmDJYvX46oqChZ3rKB/Y3MzebNm9+67siRI5g9ezaysrKQlpb2HlMZh+zGbkkPsMrU6dOnha2trfjkk0/E8ePHxdOnT8XTp0/FsWPHRNu2bYWtra04deqU1DH1olarxf3794UQQmzZskWo1WrRtWtX8cMPP4iePXsKa2trsXHjRolT6kelUmnaJkTO8w/krHDhwmLXrl1vXf/7778LLy+v95jIeN78u9WoUUOMGDFCa/3EiRNF1apVpYhmMPY3eco+r/NdX1ZWVlLHNJorV66I1q1bCysrK9G1a1dx8+ZNqSPpRW5jNws0Pf3666+iYMGCOTqlu7u72LRpk9Tx9KbkwVDJA8ann34qWrRo8db1H3/8sWjfvv17TGQ8b/7dPDw8xMmTJ7XWX7lyRba3a2B/k6dff/31rV/Dhw8X9vb2wtbWVuqYBrtz547o2bOnyJcvn2jevLk4f/681JEMJqexW54Hks1Aq1at0LBhQ/z++++aRx8FBgaiUaNGcHBwkDidcVy7dg0zZ87UWvaf//wH3333nTSBjGDx4sVwdHQEAGRkZGD58uUoWLCg1jb9+/eXIppBhg8fjmrVqqFdu3YYNmyY1u1Rpk6dit27d+Pw4cMSp9TfpUuXcO/ePdjb2+f6JIs3bykiV+xv8tGqVascy65evYoRI0Zg69at6Ny5878+g9ScJSUlYdKkSZgzZw4qVKiA6Oho1KxZU+pYRiGnsZsFmgHy58+fp/NeypYtix07dmgen2TulDoYFitWDIsWLdK89vLywooVK7S2UalUshwwKlasiLVr16Jnz57YuHGj1jo3NzesWbMGlSpVkiid4erXr695luihQ4fwwQcfaNadOXMGxYoVkyqawdjf5Nff3vT3339jzJgx+Omnn9C4cWPExMS89UkscjBt2jRMnToVXl5eWL16da7FqNzJZexmgfYe3Lx5U1aXWyt1MLx586bUEUxKTnuGuoiPj9d6nT0jk+3ly5cYPnz4+4xkVOxv8qTUWaYRI0bA3t4eJUqUwE8//YSffvop1+3+uSOoRFKP3SzQSIvSB0NdSL33pA+57BnqwtfX953r5XqVI8D+9iY5fSaVPMvUtWtXRdxWSQl4m4334J83DSV5UPLfTY5tS0hIeOd6uc400Wty+kyq1WrY29ujQYMGmluk5MYSZpmUTOrPJGfQKFccDMnc+Pn5vXPP/s2b2coN+5u8cJaJ3gcWaJQrJQ+GJE9nzpzRev3q1SucOXMG06dPx8SJEyVKZRzsb/KyfPlyqSOYRNu2bfO8LWcHTY8FGuVKyYMhyVP58uVzLAsNDYW3tze+++47nQYXc8P+Jk9JSUnIzMzM8XigxMREWFtbw9nZWaJk+nFxcZE6Ar2BBdp78OOPP8LT01PqGDpR8mBIyhIUFIQTJ05IHcMg7G/y1KFDB7Ro0QJffPGF1vKoqChs2bIFO3bskCiZfpYtWyZ1BLMi9djNAk1Hujy4OPv+Pp06dTJVnPdOCYMhydM/H7QthMDdu3cxduxYBAYGSpTKtNjfzNuxY8cwffr0HMvr1KmDkSNHSpCI3kaOYzcLNB3NmDEjT9vJ/QaMljgY/pPUe0+mJMe2ubq65jhPSwiBokWLYs2aNRKlMg72N3l+JtPT03O9kfCrV6/w4sULCRIZ1/r16xEVFYWEhAS8fPlSa93p06clSqUfOY7dvM0G5UqtVr9zMKxWrZpEyfSjz96TXCi5bW/av3+/1mu1Wo1ChQqhRIkSsLaW974m+5s81a1bF2XKlMGcOXO0lvfr1w/nzp3Dn3/+KVEyw82ePRsjR45EWFgYFi5ciPDwcMTFxeHEiRPo168fz418D1igUa6UNhj6+/vnaTuVSoUbN26YOI1xKbltloL9TZ4OHTqEBg0a4IMPPkD9+vUBANHR0Thx4gT++OMPWT9ZoFSpUhgzZgw6duyodT+w0aNHIzExEXPnzpU6ouKxQDPQ7du3sWXLllyngHM7N4GI9LdixQosWLAA8fHxOHLkCHx9fTFjxgwEBAQo6m7uJB8xMTH47rvvEBMTA3t7e5QrVw4RERGyPzSdP39+XL58Gb6+vvDw8MCuXbtQvnx5xMbGomrVqnj8+LHUEQ0ih7FbfrtmZiQ6OhotW7ZEQEAArly5gjJlyuDmzZsQQsj6wdTZOBiSOZk/fz5Gjx6NAQMGYOLEiZp7g7m5uWHmzJmy/0yyv8lThQoVsHLlSqljGJ2XlxcSExPh6+uLYsWK4ejRoyhfvjzi4+Mh93kduYzdLNAMEBERgSFDhiAyMhJOTk7YsGEDPDw80LlzZzRp0kTqeAZR+mAoh70nfSm1bXPmzMGiRYvQunVrTJkyRbM8NDQUQ4YMkTCZ4djf5OOfF3S8i9zug/amevXqYcuWLahYsSLCw8MxcOBArF+/HidPnpT9bV9kM3YL0pujo6O4fv26EEIIV1dXceHCBSGEEDExMcLX11fCZIYLDg4WmzZtEkK8bmdcXJwQQojz588Ld3d3CZMZbvfu3SJ//vyiTJkywtraWlSoUEG4uroKFxcXUbduXanjGUTJbbOzsxM3b94UQmh/Jq9duybs7OykjGYw9jf5UKlUQq1Wv/Mrexs5y8zMFK9evdK8Xr16tfjqq6/E7NmzRXp6uoTJDCeXsZszaAZwcHDQ7A0WLlwYcXFxCAkJAQA8evRIymgGi4+PR8WKFXMst7W1RUpKigSJjEc2e096UHLb/P39ERMTA19fX63lO3fuRHBwsESpjIP9TT727t0rdYT3Qq1WQ61Wa1536NABHTp0kDCR8chl7GaBZoCqVavi4MGDCA4ORrNmzTB48GCcP38eGzduRNWqVaWOZxAlD4aXL1/G6tWrAQDW1tZ48eIFHB0dMW7cOLRq1Qp9+/aVOKH+lNy2QYMGoV+/fkhLS4MQAsePH8fq1asxefJkLF68WOp4BmF/k4/atWtLHcHknj17pjk8u2PHDq17vVlZWeHjjz+WKppRyGXsZoFmgOnTpyM5ORkAEBkZieTkZKxduxaBgYGyO6/in5Q8GMpl70kfSm5bz549YW9vj2+//Rapqano1KkTvL29MWvWLNnv2bO/yY9Si5ht27Zh1KhRmufDfvrpp1qzuCqVCmvXrsUnn3wiVUSDyWbslvgQK5mxX375RZQoUUKoVCqhUqmEj4+PWLx4sdSxDNaqVSuxcOFCIYQQgwcPFiVKlBATJkwQlSpVEvXr15c4nWGU3LY3paSkiPv370sdw6jY3+Rj69atokKFCprXjo6Omr9b9vln69atkzCh/lq0aCGWLFmief3mOZFCCDF16lTRtGlTKaJZHN4HzQhevnyJBw8eICsrS2t5sWLFJEpkXKmpqUhOToaHh4fUUYzixo0bSE5ORrly5ZCSkoLBgwfj8OHDmr2nfx5mkhMlt81SsL+Zv5YtW6J169bo3r07AGjdyBUApk2bhn379snuYenA68PtO3fuRFBQEICcbTt//jzq16+PBw8eSBnTKMx97GaBZoBr166hR48eOHz4sNZyIQRUKpXmUnki0l/dunVzPAbpn1QqFaKjo99TIrJ0Si5i7OzscOXKFfj5+QEATp48ifLlyyNfvnwAXl/QUqpUKaSnp0uY0jByGbt5DpoBwsPDYW1tjW3btqFw4cL/OojIgSUNhua+92QIJbWtQoUKb133/PlzrFq1SraDBfubPD+Td+/eha2treb13r17UbRoUc1rR0dHJCUlSRHNYAUKFMD169c1BVpoaKjW+tjYWBQoUECCZMYjl7GbBZoBYmJicOrUKZQqVUrqKEaj5MEwm1z2nvShxLbNmDEjx7KMjAz88MMPmDhxInx8fDB+/HgJkhmO/U2en0klFzG1atXC7Nmz0aBBg1zXz549G7Vq1XrPqYxLLmM3CzQDlC5dWtZXIeVGyYNhNrnsPelDyW3LtnLlSowePRovXrzA2LFj0atXL1k+UBxgf5MrJRcxw4cPR7Vq1dCuXTsMGzYMJUuWBABcvXoVU6dOxe7du3MU23Ijm7FbsssTFCA6OlpUq1ZN7N27Vzx69EgkJSVpfSnBL7/8IgICAkThwoXFDz/8oHVnabnKnz+/uHz5stQxTELJbfvtt99E+fLlhbOzsxg3bpxITk6WOpLRsb/Jw+nTp4Wtra345JNPxPHjx8XTp0/F06dPxbFjx0Tbtm2Fra2tOHXqlNQx9fbrr7+KggUL5nhCgru7u+aJF3Iml7GbBZoB3rykWmmP+VDyYBgaGir+/PNPqWOYhBLbduzYMVGnTh1hZ2cnBgwYIB4+fCh1JKNjf5MfpRcxKSkpYuPGjWLq1Kli6tSpYuPGjYr5XMpl7OZVnAbYv3//O9fL8Y7Tx48fx/Dhw3H06FH06dMHI0eORMGCBaWOZVR79uzBt99+i0mTJqFs2bKaq5OyyfkBx0psm1qthr29PXr16gV/f/+3bte/f//3mMo42N/k+ZnMlpqait9//x2xsbEAgMDAQDRq1AgODg4SJ3t/ypYtix07dmhdJGHu5DJ2s0AjLUoeDLNlP1/un+fCCBmftJxNiW3z8/PL05WON27ceE+JjIf9TZ6fSV3JsYjJq3/eYoSMhwWajs6dO4cyZcpArVbj3Llz79y2XLly7ymV8Sh5MMwml70nfSi5bUrE/mYZn0klFzFyaZscx24WaDpSq9W4d+8ePDw8oFaroVKpkNuv0FL2DInMjZJnK0ie5FLE6EMubZPj2C3Pa9MlFB8fj0KFCmn+benkMhjKce8pr5TcNn3cvHkTr169kjqGSbC/EelHjmM3Z9DIINx7kp6S26YPuXwm9SGXtvEzqU0ufzd9KLltUuMMmoH+/vtvHDx4MNdHmMj5xF6lkePeU14puW0kT/xMkrmTw9jNAs0Ay5cvR+/evWFjYwN3d3etk31VKpXZ/JEJ8PX1zfXfSqDktpE88TNpOX788Ud4enpKHUMnchm7WaAZYNSoURg9ejQiIiI0l5KTPMhh70lfSm4byZOlfyblUsTMnj07z9tm/906depkqjgmI5exm+egGcDd3R3Hjx9H8eLFpY4iGTmef/Bve09yvqWBktuWV3L8TOaVHNumtM+kPkWMXLzrXnxvkuPf7U1yGbtZoBlg2LBhKFCgAEaMGCF1FMnIccAoWrQo+vTpY/Z7T/pQctvyatWqVWjVqpUi7+bO/iY9SylilEwuYzcLNANkZmaiefPmePHiRa6PMJk+fbpEyd4fOQ6Gctl70ofS2qbk2Qp9sL8RGU4uYzcLNANMmDABo0ePRlBQEDw9PXNM3e/Zs0fCdLqzlMFQLntP+lBa25Q8W8H+Rubu9u3b2LJlCxISEvDy5UutdeZSxOhDLmM3CzQDuLm5YcaMGQgLC5M6ilEoeTB8k1z2nvSh5LYpDfvba3L/TCq1iImOjkbLli0REBCAK1euoEyZMrh58yaEEKhUqZLZFDH6kMvYzas4DWBra4vq1atLHcNoLOV+RZMnT8bvv/+OoKAgAMix9yRnSm6b0rC/yf8z+W9FjJxFRERgyJAhiIyMhJOTEzZs2AAPDw907twZTZo0kTqeQeQydnMGzQCTJ0/G3bt3dTpUQdKTy96TPpTcNkC5sxVKpuTPZJUqVdC0aVNNEXP27FmtIqZv375SR9Sbk5MTYmJiULx4cbi5ueHgwYMICQnB2bNn0apVK9y8eVPqiHqTy9jNGTQDHD9+HHv27MG2bdsQEhKSY+p+48aNEiUzDqUOhnLZe9KHktum5NkKgP1Nji5fvozVq1cDAKytrfHixQs4Ojpi3LhxaNWqlawLNAcHB83nsHDhwoiLi0NISAgA4NGjR1JGM5hcxm4WaAZwdXVF27ZtpY5hEkoeDL/++mvMmTPH7Pee9KHktin5kAv7mzwpuYipWrUqDh48iODgYDRr1gyDBw/G+fPnsXHjRlStWlXqeAaRy9jNQ5x6ysjIwKpVq9CoUSN4eXlJHcfolDx136ZNG+zZswfu7u5mvfekDyW3TcmHXNjf5Kl169b4+OOP8fnnn2PIkCHYvHkzwsLCsHHjRri5uWH37t1SR9TbjRs3kJycjHLlyiElJQWDBw/G4cOHERgYiOnTp8v2EV5yGrs5g6Yna2tr9OnTB5cvX5Y6ikkoeepeLntP+lBy25Q8W8H+Jk/Tp09HcnIyACAyMhLJyclYu3atpoiRszdvhuzg4IAFCxZImMZ45DR2s0AzQJUqVXDmzBnZ7km8i1IHw4yMDNStW1cWe0+6UnLbAGUfcmF/kyelFjFvevnyZa7PUC1WrJhEiQwnl7GbBZoBvvjiCwwePBi3b99G5cqVc9zdu1y5chIlM5xSB0M57T3pSsltA5Q9W8H+Jm9KLGKuXbuGHj164PDhw1rLhRBQqVTIzMyUKJnh5DJ28xw0A+T2XDmVSqWID7BSzz8AgDp16mDAgAFo3bq11FGMTsltUzL2N3lSchFTvXp1WFtbY8SIEShcuHCOe9aVL19eomSGk8vYzQLNALdu3Xrnejn/p6pkUVFRiIiIwMCBA81670kfSm5bNiXOViiZkj+TSi5iHBwccOrUKZQqVUrqKEYnl7GbBRq9kxIHQ7nsPelDyW1T8mxFNvY3eVFyEfPBBx9gxowZqFGjhtRRLBbPQTPQihUrsGDBAsTHx+PIkSPw9fXFzJkz4e/vj1atWkkdT29KHgyV/IgdJbctPDwc1tbW2LZtW66zFXLG/iZPpUuXlvVFHO8ydepUDBs2DJMmTcr1GarOzs4SJTMOOYzdLNAMMH/+fIwePRoDBgzAxIkTNf+Jurq6YubMmWbzR9aHkgdDc5m+NgUlty0mJkaxsxXsb/Kk5CKmQYMGAID69etrLVfCToNcxm4e4jRA6dKlMWnSJLRu3Vpzc8mAgABcuHABderUkfWelZKn7gF57D3pS6ltU/IhF/Y3eco+fPvPgloJRcz+/fvfub527drvKYnxyWXs5gyaAeLj41GxYsUcy21tbZGSkiJBIuNR8tS9XPae9KHktil5toL9TZ727t0rdQSTkXMB9m9kM3YL0ltwcLD49ddfhRBCODo6iri4OCGEELNnzxYVK1aUMprBoqOjRbVq1cTevXvFo0ePRFJSktaXnAUHB4tNmzYJIbT/bufPnxfu7u4SJjOcktumUqmESqUSarVa6yt7mZyxv5E5OHv2rMjMzNT8+11fciaXsZszaHoYN24chgwZgkGDBqFfv35IS0uDEALHjx/H6tWrMXnyZCxevFjqmAZR8vkHstl70oOS26bk2Qr2N/k4d+4cypQpA7VajXPnzr1zW7ndQqRChQq4d+8ePDw8UKFCBc3Vtv8k18+k3MZuFmh6iIyMRJ8+fdCzZ0/Y29vj22+/RWpqKjp16gRvb2/MmjULHTp0kDqmQZQ8GPr7+yMmJibHycs7d+5EcHCwRKmMQ8ltU/IhF/Y3+VByERMfH49ChQpp/q00chu7WaDp4c3O2LlzZ3Tu3BmpqalITk6Gh4eHhMmMR4mDodz2nnSh1LYpebbiTexv8qHkIubNIlqJV9/KbezmVZx6UKvVuH//vqaTKoXSB0MrKyvcvXsXHh4eWLlyJcaOHYu4uDgAgLe3NyIjI9GjRw+JU+pHqW1Tq9Wa2Qq1Wq2o2Qr2N3l+Ji3J33//jYMHD+Z68+T+/ftLlEp/chu7WaDpQa1Ww8XF5V/vVZSYmPieEhmHkgdDQLt92cx570kXSm3brVu3UKxYMahUKtk8niWv2N+UQWlFTLbly5ejd+/esLGxgbu7u9Z4p1KpcOPGDQnT6UduYzcPceopMjISLi4uUscwKiVP3Wf7Z8fMnz8/8ufPL1Ea41Ji25R8yIX9Tf7+rYiRc4E2atQojB49GhEREbk+rkuu5DR2cwZND7ntGZL5k9veky6U3LY3KXW2Qoks4TNZtGhR9OnTR3FFDAC4u7vj+PHjKF68uNRRjEZuYzdn0PSgpMewvIsSB0M57T3pSsltA5Q9WwGwv8lRamoqOnTooLjiDAB69OiBdevWYcSIEVJHMRq5jd2cQdOD3KpwfSj1/AOl/t2U3LZsSp6tYH+Tp2HDhqFAgQKKKmKyZWZmonnz5njx4kWuT+6YPn26RMn0J7fPJAs0ypUSB8M3rypTGiW3LZsSD7lkY3+TJyUWMdkmTJiA0aNHIygoCJ6enjl2Gvbs2SNhOsvAQ5yUKyVO3St5X0TJbcumxEMu2djf5Gny5Mn4/fffERQUBAA5ihg5+/7777F06VKEhYVJHcVicQaNcqXkqXuSJyXPVrC/yZObmxtmzJihyCLGy8sLf/75JwIDA6WOYrFYoFGulDwYkjwp+ZAL+5s8KbmImTx5Mu7evYvZs2dLHcVi8RAn5UrJU/ckT0o+5ML+Jk9ff/015syZo8gi5vjx49izZw+2bduGkJCQHDsNGzdulCiZ5eAMGuVKyVP3JE9Knq1gf5OnNm3aYM+ePXB3d1dcERMeHv7O9cuWLXtPSSwXZ9AoV7a2tqhevbrUMYg0lDxbwf4mT66urmjbtq3UMYwuIyMDdevWRaNGjeDl5SV1HIvFGTTKFc8/IHOj5NkK9jf5ycjIwKpVqxRbxOTPnx+XL19W3CPW5IQzaJQrnn9A5kapsxUA+5scWVtbo0+fPrh8+bLUUUyiSpUqOHPmDAs0CbFAo1wpeTAk+VH6IRf2N3lSchHzxRdfYPDgwbh9+zYqV64MBwcHrfXlypWTKJnl4CFOykHpU/ckT0o95ML+Jl9RUVGIiIjAwIEDFVfE5HbTZJVKBSEEVCoVMjMzJUhlWVigUa6UOhiSfNWpUwcDBgxA69atpY5idOxv8qTkIubWrVvvXM/PqunxECflSslT9yRPSj7kwv4mT/Hx8VJHMBl+FqXHGTTKlZKn7kmelDxbwf5G5mjFihVYsGAB4uPjceTIEfj6+mLmzJnw9/dHq1atpI6neCzQKFdKHgxJnpR8yIX9Tb6UWsTMnz8fo0ePxoABAzBx4kRcuHABAQEBWL58OX766Sfs3btX6oiKx0OclCslT92TPMm5APs37G/y9M8iJruQdnV1xcyZM2VdoM2ZMweLFi1C69atMWXKFM3y0NBQDBkyRMJkloMzaEQkG0qdrSB5Kl26NCZNmoTWrVvDyckJZ8+eRUBAAC5cuIA6derg0aNHUkfUm729Pa5cuQJfX1+ttsXGxqJcuXJ48eKF1BEVL+e8OtH/rFixAtWrV4e3t7fm8NLMmTOxefNmiZORJZo/fz4GDRqEZs2a4enTpzlmK+SO/U1+4uPjUbFixRzLbW1tkZKSIkEi4/H390dMTEyO5Tt37kRwcPD7D2SBWKBRrpQ+GJL8ZB9yGTlyJKysrDTLQ0NDcf78eQmTGY79TZ6UWMSMGzcOqampGDRoEPr164e1a9dCCIHjx49j4sSJiIiIwLBhw6SOaRkEUS6Cg4PFpk2bhBBCODo6iri4OCGEEOfPnxfu7u4SJiNLZWdnJ27evCmE0P5MXrt2TdjZ2UkZzWDsb/ISGRkpUlJSxKJFi4SPj49Ys2aNcHBwEKtXrxYTJkzQ/FuO1Gq1uH//vhBCiF9++UWUKFFCqFQqoVKphI+Pj1i8eLHECS0HLxKgXCl56p7kKXu24p8XC8h5tiIb+5u8REZGok+fPujZsyfs7e3x7bffIjU1FZ06dYK3tzdmzZqFDh06SB1TL+KN09I7d+6Mzp07IzU1FcnJyfDw8JAwmeVhgUa5UvJgSPIybtw4DBkyRHPIJS0tTXPIZfXq1Zg8eTIWL14sdUyDsL/Ji9KLGJVKpfU6f/78yJ8/v0RpLBcLNNJiCYMhyYuSZyvY3+RLyUVMyZIlc7TvnxITE99TGsvF22yQFisrK9y9exceHh5YuXIlxo4di7i4OACAt7c3IiMj0aNHD4lTkiVRq9W4d++e1syEUmYr2N/kSa1Ww8XFRZFFjFqtxsyZM+Hi4vLO7bp16/aeElkuFmikRcmDIcmTWq3G/fv3UahQIamjGB37mzwpuYjJ7TNJ0uAhTspByVP3JE9KPuTC/iZPHTp0UGQR82/9jN4fFmiUg5IHQ5KnyMjIf52tkCv2N/lRchHDg2rmgwUa5aDkwZDkSamzFQD7mxwpuYjJysqSOgL9D89BIy08/4DMzZsn0isN+xsRvQ0f9URalDx1T/Kk5H1I9jciehse4iQtSh4MSZ6UfMiF/Y2I3oaHOImIiIjMDA9xEhEREZkZFmhEREREZoYFGhEREZGZYYFGREREZGZYoBERmamwsDC0bt06z9vfvHkTKpUKMTExb91m3759UKlUePr0qcH5iMh0WKAR0VvpWiC8b3kpSPSVl0Jmw4YNsLKywp07d3JdHxgYiEGDBumdYdasWVi+fLne309E8sUCjYhk6eXLl1JHQMuWLeHu7o6ffvopx7oDBw7g+vXr6NGjh87vm5mZiaysLLi4uMDV1dUISYlIbligEVGe1alTB1999RUGDBgANzc3eHp6YtGiRUhJSUF4eDicnJxQokQJ/Pbbb5rvyZ6J2r59O8qVKwc7OztUrVoVFy5c0HrvDRs2ICQkBLa2tvDz88P333+vtd7Pzw/jx49H165d4ezsjF69esHf3x8AULFiRahUKtSpUwcAcOLECTRs2BAFCxaEi4sLateujdOnT2u9n0qlwuLFi9GmTRvkz58fgYGB2LJlC4DXM3N169YFALi5uUGlUiEsLCzH7yNfvnzo0qVLrrNcS5cuxYcffoiQkBBMnz4dZcuWhYODA4oWLYovvvgCycnJmm2XL18OV1dXbNmyBaVLl4atrS0SEhJyzGDu3LkTNWrUgKurK9zd3dG8eXPExcXl+NlXrlzBRx99BDs7O5QpUwb79+/Psc2bDh48iJo1a8Le3h5FixZF//79kZKSolk/b948BAYGws7ODp6envjkk0/e+X5EZASCiOgtunXrJlq1aqV5Xbt2beHk5CTGjx8vrl27JsaPHy+srKxE06ZNxcKFC8W1a9dE3759hbu7u0hJSRFCCLF3714BQAQHB4s//vhDnDt3TjRv3lz4+fmJly9fCiGEOHnypFCr1WLcuHHi6tWrYtmyZcLe3l4sW7ZM87N9fX2Fs7Oz+O9//yuuX78url+/Lo4fPy4AiN27d4u7d++Kx48fCyGEiI6OFitWrBCXL18Wly5dEj169BCenp7i2bNnmvcDIIoUKSJWrVolYmNjRf/+/YWjo6N4/PixyMjIEBs2bBAAxNWrV8Xdu3fF06dPc/0dXbx4UQAQ+/fv1yx7/vy5cHBwEAsXLhRCCDFjxgyxZ88eER8fL6Kjo0VQUJDo27evZvtly5aJfPnyiY8++kgcOnRIXLlyRaSkpOT4/a9fv15s2LBBxMbGijNnzogWLVqIsmXLiszMTCGEEPHx8Zp2rV+/Xly6dEn07NlTODk5iUePHmn9PZ48eSKEEOL69evCwcFBzJgxQ1y7dk0cOnRIVKxYUYSFhQkhhDhx4oSwsrISq1atEjdv3hSnT58Ws2bNyvNniIj0wwKNiN4qtwKtRo0amtcZGRnCwcFBdOnSRbPs7t27AoA4cuSIEOL/C4I1a9Zotnn8+LGwt7cXa9euFUII0alTJ9GwYUOtnz106FBRunRpzWtfX1/RunVrrW2yC5IzZ868sx2ZmZnCyclJbN26VbMMgPj22281r5OTkwUA8dtvv2nlzi5k3qVq1aqiW7dumtdLliwR+fPn1yoI37Ru3Trh7u6ueb1s2TIBQMTExGht98/f/z89fPhQABDnz58XQvz/72PKlCmabV69eiWKFCkipk6dmmu7evToIXr16qX1vn/++adQq9XixYsXYsOGDcLZ2fmtbSEi0+AhTiLSSbly5TT/trKygru7O8qWLatZ5unpCQB48OCB1vdVq1ZN8+8CBQogKCgIly9fBgBcvnwZ1atX19q+evXqiI2NRWZmpmZZaGhonjLev38fn3/+OQIDA+Hi4gJnZ2ckJycjISHhrW1xcHCAs7Nzjtx50b17d6xfvx7Pnz8H8PrwZrt27eDk5AQA2L17N+rXrw8fHx84OTmhS5cuePz4MVJTUzXvYWNjo5UnN7GxsejYsSMCAgLg7OwMPz8/AMjRrjd/19bW1ggNDdX8rv/p7NmzWL58ORwdHTVfjRs3RlZWFuLj49GwYUP4+voiICAAXbp0wcqVK7VyE5FpsEAjIp3ky5dP67VKpdJaplKpAJjmIecODg552q5bt26IiYnBrFmzcPjwYcTExMDd3T3HhQW5tUWf3B06dAAAREVFITY2FocOHdJcHHDz5k00b94c5cqVw4YNG3Dq1Cn88MMPALQvdLC3t9f87t6mRYsWSExMxKJFi3Ds2DEcO3Ysx/voKjk5Gb1790ZMTIzm6+zZs4iNjUXx4sXh5OSE06dPY/Xq1ShcuDBGjx6N8uXL8zYdRCZmLXUAIrIMR48eRbFixQAAT548wbVr1xAcHAwACA4OxqFDh7S2P3ToEEqWLAkrK6u3vqeNjQ0AaM2yZX/vvHnz0KxZMwDAX3/9hUePHumU923vnRsnJye0a9cOS5cuRVxcHEqWLImaNWsCAE6dOoWsrCx8//33UKtf7xNHRUXplAUAHj9+jKtXr2LRokWa9z548GCu2x49ehS1atUCAGRkZODUqVP48ssvc922UqVKuHTpEkqUKPHWn21tbY0GDRqgQYMGGDNmDFxdXbFnzx60bdtW53YQUd6wQCOi92LcuHFwd3eHp6cnRo4ciYIFC2quUBw8eDA++OADjB8/Hp9++imOHDmCuXPnYt68ee98Tw8PD9jb22Pnzp0oUqQI7Ozs4OLigsDAQKxYsQKhoaF49uwZhg4dCnt7e53y+vr6QqVSYdu2bWjWrBns7e3h6Oj41u179OiBmjVr4vLlyxg+fLhmeYkSJfDq1SvMmTMHLVq0wKFDh7BgwQKdsgCvryZ1d3fHwoULUbhwYSQkJGDEiBG5bvvDDz8gMDAQwcHBmDFjBp48eYLu3bvnuu3w4cNRtWpVfPnll+jZsyccHBxw6dIl7Nq1C3PnzsW2bdtw48YN1KpVC25ubtixYweysrIQFBSkcxuIKO94iJOI3ospU6bg66+/RuXKlXHv3j1s3bpVM0tVqVIlREVFYc2aNShTpgxGjx6NcePG5XprizdZW1tj9uzZ+PHHH+Ht7Y1WrVoBAJYsWYInT56gUqVK6NKlC/r37w8PDw+d8vr4+CAyMhIjRoyAp6fnW2egstWoUQNBQUF49uwZunbtqllevnx5TJ8+HVOnTkWZMmWwcuVKTJ48WacsAKBWq7FmzRqcOnUKZcqUwcCBA/Hdd9/luu2UKVMwZcoUlC9fHgcPHsSWLVtQsGDBXLctV64c9u/fj2vXrqFmzZqoWLEiRo8eDW9vbwCAq6srNm7ciHr16iE4OBgLFizA6tWrERISonMbiCjvVEIIIXUIIlKuffv2oW7dunjy5AlvukpElEecQSMiIiIyMyzQiIiIiMwMD3ESERERmRnOoBERERGZGRZoRERERGaGBRoRERGRmWGBRkRERGRmWKARERERmRkWaERERERmhgUaERERkZlhgUZERERkZligEREREZmZ/wPnk6JfaZJY+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_ml_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-greene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model:xgboost.sklearn.XGBModel,\n",
       ">                    X_test:pandas.core.frame.DataFrame, y_test:List, n:int=10)\n",
       "\n",
       "*analyzes misclassifications of trained machine learning model*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | XGBModel |  | trained ML model from train_ml_model |\n",
       "| X_test | DataFrame |  | motif dataframe for validation |\n",
       "| y_test | List |  | test labels |\n",
       "| n | int | 10 | number of returned misclassifications |\n",
       "| **Returns** | **List** |  | **misclassifications and predicted probabilities** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_mismatch\n",
       "\n",
       ">      get_mismatch (model:xgboost.sklearn.XGBModel,\n",
       ">                    X_test:pandas.core.frame.DataFrame, y_test:List, n:int=10)\n",
       "\n",
       "*analyzes misclassifications of trained machine learning model*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | XGBModel |  | trained ML model from train_ml_model |\n",
       "| X_test | DataFrame |  | motif dataframe for validation |\n",
       "| y_test | List |  | test labels |\n",
       "| n | int | 10 | number of returned misclassifications |\n",
       "| **Returns** | **List** |  | **misclassifications and predicted probabilities** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-basket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gal(b1-4)GlcNAc(b1-6)[Gal(b1-3)]Gal(b1-4)Glc-ol', 0.8661944270133972),\n",
       " ('Man(a1-2)Man(a1-2)Man(a1-3)[Man(a1-2)Man(a1-3)[Man(a1-2)Man(a1-6)]Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc',\n",
       "  0.814888596534729),\n",
       " ('Neu5Ac(a2-8)Neu5Ac(a2-3)Gal(b1-4)Glc1Cer', 0.8540824055671692),\n",
       " ('Gal(b1-4)Glc-ol', 0.7748590111732483),\n",
       " ('Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-?)]Man(a1-?)[GlcNAc(b1-2)Man(a1-?)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.9565786123275757),\n",
       " ('Gal(b1-3)GlcNAc(b1-3)Gal(b1-4)Glc-ol', 0.812296450138092),\n",
       " ('Fuc(a1-4)GlcNAc(b1-3)Gal(b1-4)[Fuc(a1-3)]Glc-ol', 0.8908309936523438),\n",
       " ('Neu5Ac(a2-6)Gal(b1-?)[Fuc(a1-?)]GlcNAc(b1-?)[Fuc(a1-?)[Gal(b1-?)]GlcNAc(b1-?)]Man(a1-3)[Gal(b1-?)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.612709641456604),\n",
       " ('Neu5Ac(a2-3)Gal(b1-?)GlcNAc(b1-2)Man(a1-3)[Neu5Ac(a2-3)Gal(b1-?)[Neu5Ac(a2-6)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc',\n",
       "  0.9313767552375793),\n",
       " ('GalNAc(b1-4)Gal(b1-4)GlcNAc(b1-6)[GalNAc(a1-3)Gal(b1-3)]GalNAc',\n",
       "  0.9005035161972046)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mismatch(model_ft, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-stadium",
   "metadata": {},
   "source": [
    "## models\n",
    ">describes some examples for machine learning architectures applicable to glycans. The main portal is prep_models which allows users to setup (trained) models by their string names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size:int, num_classes:int=1, hidden_dim:int=128)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| lib_size | int |  | number of unique tokens for graph nodes |\n",
       "| num_classes | int | 1 | number of output classes (>1 for multilabel) |\n",
       "| hidden_dim | int | 128 | dimension of hidden layers |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SweetNet\n",
       "\n",
       ">      SweetNet (lib_size:int, num_classes:int=1, hidden_dim:int=128)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| lib_size | int |  | number of unique tokens for graph nodes |\n",
       "| num_classes | int | 1 | number of output classes (>1 for multilabel) |\n",
       "| hidden_dim | int | 128 | dimension of hidden layers |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SweetNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco:int, hidden_size:int=128,\n",
       ">                    num_classes:int=1, data_min:float=-11.355,\n",
       ">                    data_max:float=23.892, input_size_prot:int=1280)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| input_size_glyco | int |  | number of unique tokens for graph nodes |\n",
       "| hidden_size | int | 128 | layer size for graph convolutions |\n",
       "| num_classes | int | 1 | number of output classes (>1 for multilabel) |\n",
       "| data_min | float | -11.355 | minimum observed value in training data |\n",
       "| data_max | float | 23.892 | maximum observed value in training data |\n",
       "| input_size_prot | int | 1280 | dimensionality of protein representations |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle\n",
       "\n",
       ">      LectinOracle (input_size_glyco:int, hidden_size:int=128,\n",
       ">                    num_classes:int=1, data_min:float=-11.355,\n",
       ">                    data_max:float=23.892, input_size_prot:int=1280)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| input_size_glyco | int |  | number of unique tokens for graph nodes |\n",
       "| hidden_size | int | 128 | layer size for graph convolutions |\n",
       "| num_classes | int | 1 | number of output classes (>1 for multilabel) |\n",
       "| data_min | float | -11.355 | minimum observed value in training data |\n",
       "| data_max | float | 23.892 | maximum observed value in training data |\n",
       "| input_size_prot | int | 1280 | dimensionality of protein representations |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LectinOracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-passion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco:int, hidden_size:int=128,\n",
       ">                         num_classes:int=1, data_min:float=-11.355,\n",
       ">                         data_max:float=23.892, input_size_prot:int=1000)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| input_size_glyco | int |  | number of unique tokens for graph nodes |\n",
       "| hidden_size | int | 128 | layer size for graph convolutions |\n",
       "| num_classes | int | 1 | number of output classes (>1 for multilabel) |\n",
       "| data_min | float | -11.355 | minimum observed value in training data |\n",
       "| data_max | float | 23.892 | maximum observed value in training data |\n",
       "| input_size_prot | int | 1000 | maximum protein sequence length for padding/cutting |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LectinOracle_flex\n",
       "\n",
       ">      LectinOracle_flex (input_size_glyco:int, hidden_size:int=128,\n",
       ">                         num_classes:int=1, data_min:float=-11.355,\n",
       ">                         data_max:float=23.892, input_size_prot:int=1000)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| input_size_glyco | int |  | number of unique tokens for graph nodes |\n",
       "| hidden_size | int | 128 | layer size for graph convolutions |\n",
       "| num_classes | int | 1 | number of output classes (>1 for multilabel) |\n",
       "| data_min | float | -11.355 | minimum observed value in training data |\n",
       "| data_max | float | 23.892 | maximum observed value in training data |\n",
       "| input_size_prot | int | 1000 | maximum protein sequence length for padding/cutting |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LectinOracle_flex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### NSequonPred\n",
       "\n",
       ">      NSequonPred ()\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing them to be nested in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self) -> None:\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will also have their\n",
       "parameters converted when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NSequonPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model:torch.nn.modules.module.Module, mode:str='sparse',\n",
       ">                    sparsity:float=0.1)\n",
       "\n",
       "*initializes linear layers of PyTorch model with a weight initialization*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | neural network for analyzing glycans |\n",
       "| mode | str | sparse | initialization algorithm: 'sparse', 'kaiming', 'xavier' |\n",
       "| sparsity | float | 0.1 | proportion of sparsity after initialization |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### init_weights\n",
       "\n",
       ">      init_weights (model:torch.nn.modules.module.Module, mode:str='sparse',\n",
       ">                    sparsity:float=0.1)\n",
       "\n",
       "*initializes linear layers of PyTorch model with a weight initialization*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | Module |  | neural network for analyzing glycans |\n",
       "| mode | str | sparse | initialization algorithm: 'sparse', 'kaiming', 'xavier' |\n",
       "| sparsity | float | 0.1 | proportion of sparsity after initialization |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-cooler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type:Literal['SweetNet','LectinOracle','LectinOracle_fl\n",
       ">                  ex','NSequonPred'], num_classes:int,\n",
       ">                  libr:Optional[Dict[str,int]]=None, trained:bool=False,\n",
       ">                  hidden_dim:int=128)\n",
       "\n",
       "*wrapper to instantiate model, initialize it, and put it on the GPU*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_type | Literal |  | type of model to create |\n",
       "| num_classes | int |  | number of unique classes for classification |\n",
       "| libr | Optional | None | dictionary of form glycoletter:index |\n",
       "| trained | bool | False | whether to use pretrained model |\n",
       "| hidden_dim | int | 128 | hidden dimension for the model (SweetNet/LectinOracle only) |\n",
       "| **Returns** | **Module** |  | **initialized PyTorch model** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prep_model\n",
       "\n",
       ">      prep_model (model_type:Literal['SweetNet','LectinOracle','LectinOracle_fl\n",
       ">                  ex','NSequonPred'], num_classes:int,\n",
       ">                  libr:Optional[Dict[str,int]]=None, trained:bool=False,\n",
       ">                  hidden_dim:int=128)\n",
       "\n",
       "*wrapper to instantiate model, initialize it, and put it on the GPU*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_type | Literal |  | type of model to create |\n",
       "| num_classes | int |  | number of unique classes for classification |\n",
       "| libr | Optional | None | dictionary of form glycoletter:index |\n",
       "| trained | bool | False | whether to use pretrained model |\n",
       "| hidden_dim | int | 128 | hidden dimension for the model (SweetNet/LectinOracle only) |\n",
       "| **Returns** | **Module** |  | **initialized PyTorch model** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(prep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-registrar",
   "metadata": {},
   "source": [
    "## processing\n",
    ">contains helper functions to prepare glycan data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-closer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list:List[str], labels:List[Union[float,int]],\n",
       ">                         libr:Optional[Dict[str,int]]=None,\n",
       ">                         label_type:torch.dtype=torch.int64)\n",
       "\n",
       "*wrapper function to convert a whole list of glycans into a graph dataset*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycan_list | List |  | list of IUPAC-condensed glycan sequences |\n",
       "| labels | List |  | list of labels |\n",
       "| libr | Optional | None | dictionary of glycoletter:index |\n",
       "| label_type | dtype | torch.int64 | tensor type for label |\n",
       "| **Returns** | **List** |  | **list of node/edge/label data tuples** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_graphs\n",
       "\n",
       ">      dataset_to_graphs (glycan_list:List[str], labels:List[Union[float,int]],\n",
       ">                         libr:Optional[Dict[str,int]]=None,\n",
       ">                         label_type:torch.dtype=torch.int64)\n",
       "\n",
       "*wrapper function to convert a whole list of glycans into a graph dataset*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycan_list | List |  | list of IUPAC-condensed glycan sequences |\n",
       "| labels | List |  | list of labels |\n",
       "| libr | Optional | None | dictionary of glycoletter:index |\n",
       "| label_type | dtype | torch.int64 | tensor type for label |\n",
       "| **Returns** | **List** |  | **list of node/edge/label data tuples** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(dataset_to_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 8], labels=[5], string_labels=[5], num_nodes=5, y=1),\n",
       " Data(edge_index=[2, 8], labels=[5], string_labels=[5], num_nodes=5, y=0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_graphs([\"Neu5Ac(a2-3)Gal(b1-4)Glc\",\n",
    "                  \"Fuc(a1-2)Gal(b1-3)GalNAc\"], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list:List[str],\n",
       ">                             labels:List[Union[float,int]],\n",
       ">                             libr:Optional[Dict[str,int]]=None,\n",
       ">                             batch_size:int=32, shuffle:bool=True,\n",
       ">                             drop_last:bool=False,\n",
       ">                             extra_feature:Optional[List[float]]=None,\n",
       ">                             label_type:torch.dtype=torch.int64,\n",
       ">                             augment_prob:float=0.0,\n",
       ">                             generalization_prob:float=0.2)\n",
       "\n",
       "*wrapper function to convert glycans and labels to a torch_geometric DataLoader*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycan_list | List |  | list of IUPAC-condensed glycans |\n",
       "| labels | List |  | list of labels |\n",
       "| libr | Optional | None | dictionary of glycoletter:index |\n",
       "| batch_size | int | 32 | samples per batch |\n",
       "| shuffle | bool | True | shuffle samples in dataloader |\n",
       "| drop_last | bool | False | drop last batch |\n",
       "| extra_feature | Optional | None | additional input features |\n",
       "| label_type | dtype | torch.int64 | tensor type for label |\n",
       "| augment_prob | float | 0.0 | probability of data augmentation |\n",
       "| generalization_prob | float | 0.2 | probability of wildcarding |\n",
       "| **Returns** | **DataLoader** |  | **dataloader for training** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### dataset_to_dataloader\n",
       "\n",
       ">      dataset_to_dataloader (glycan_list:List[str],\n",
       ">                             labels:List[Union[float,int]],\n",
       ">                             libr:Optional[Dict[str,int]]=None,\n",
       ">                             batch_size:int=32, shuffle:bool=True,\n",
       ">                             drop_last:bool=False,\n",
       ">                             extra_feature:Optional[List[float]]=None,\n",
       ">                             label_type:torch.dtype=torch.int64,\n",
       ">                             augment_prob:float=0.0,\n",
       ">                             generalization_prob:float=0.2)\n",
       "\n",
       "*wrapper function to convert glycans and labels to a torch_geometric DataLoader*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycan_list | List |  | list of IUPAC-condensed glycans |\n",
       "| labels | List |  | list of labels |\n",
       "| libr | Optional | None | dictionary of glycoletter:index |\n",
       "| batch_size | int | 32 | samples per batch |\n",
       "| shuffle | bool | True | shuffle samples in dataloader |\n",
       "| drop_last | bool | False | drop last batch |\n",
       "| extra_feature | Optional | None | additional input features |\n",
       "| label_type | dtype | torch.int64 | tensor type for label |\n",
       "| augment_prob | float | 0.0 | probability of data augmentation |\n",
       "| generalization_prob | float | 0.2 | probability of wildcarding |\n",
       "| **Returns** | **DataLoader** |  | **dataloader for training** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(dataset_to_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 16], labels=[10], string_labels=[2], num_nodes=10, y=[2], batch=[10], ptr=[3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_to_dataloader([\"Neu5Ac(a2-3)Gal(b1-4)Glc\",\n",
    "                                 \"Fuc(a1-2)Gal(b1-3)GalNAc\"], [1, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train:List[str],\n",
       ">                           glycan_list_val:List[str],\n",
       ">                           labels_train:List[Union[float,int]],\n",
       ">                           labels_val:List[Union[float,int]],\n",
       ">                           libr:Optional[Dict[str,int]]=None,\n",
       ">                           batch_size:int=32, drop_last:bool=False,\n",
       ">                           extra_feature_train:Optional[List[float]]=None,\n",
       ">                           extra_feature_val:Optional[List[float]]=None,\n",
       ">                           label_type:torch.dtype=torch.int64,\n",
       ">                           augment_prob:float=0.0,\n",
       ">                           generalization_prob:float=0.2)\n",
       "\n",
       "*wrapper function to convert split training/test data into dictionary of dataloaders*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycan_list_train | List |  | training glycans |\n",
       "| glycan_list_val | List |  | validation glycans |\n",
       "| labels_train | List |  | training labels |\n",
       "| labels_val | List |  | validation labels |\n",
       "| libr | Optional | None | dictionary of glycoletter:index |\n",
       "| batch_size | int | 32 | samples per batch |\n",
       "| drop_last | bool | False | drop last batch |\n",
       "| extra_feature_train | Optional | None | additional training features |\n",
       "| extra_feature_val | Optional | None | additional validation features |\n",
       "| label_type | dtype | torch.int64 | tensor type for label |\n",
       "| augment_prob | float | 0.0 | probability of data augmentation |\n",
       "| generalization_prob | float | 0.2 | probability of wildcarding |\n",
       "| **Returns** | **Dict** |  | **dictionary of train/val dataloaders** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### split_data_to_train\n",
       "\n",
       ">      split_data_to_train (glycan_list_train:List[str],\n",
       ">                           glycan_list_val:List[str],\n",
       ">                           labels_train:List[Union[float,int]],\n",
       ">                           labels_val:List[Union[float,int]],\n",
       ">                           libr:Optional[Dict[str,int]]=None,\n",
       ">                           batch_size:int=32, drop_last:bool=False,\n",
       ">                           extra_feature_train:Optional[List[float]]=None,\n",
       ">                           extra_feature_val:Optional[List[float]]=None,\n",
       ">                           label_type:torch.dtype=torch.int64,\n",
       ">                           augment_prob:float=0.0,\n",
       ">                           generalization_prob:float=0.2)\n",
       "\n",
       "*wrapper function to convert split training/test data into dictionary of dataloaders*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycan_list_train | List |  | training glycans |\n",
       "| glycan_list_val | List |  | validation glycans |\n",
       "| labels_train | List |  | training labels |\n",
       "| labels_val | List |  | validation labels |\n",
       "| libr | Optional | None | dictionary of glycoletter:index |\n",
       "| batch_size | int | 32 | samples per batch |\n",
       "| drop_last | bool | False | drop last batch |\n",
       "| extra_feature_train | Optional | None | additional training features |\n",
       "| extra_feature_val | Optional | None | additional validation features |\n",
       "| label_type | dtype | torch.int64 | tensor type for label |\n",
       "| augment_prob | float | 0.0 | probability of data augmentation |\n",
       "| generalization_prob | float | 0.2 | probability of wildcarding |\n",
       "| **Returns** | **Dict** |  | **dictionary of train/val dataloaders** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(split_data_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch_geometric.loader.dataloader.DataLoader>,\n",
       " 'val': <torch_geometric.loader.dataloader.DataLoader>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data_to_train([\"Neu5Ac(a2-3)Gal(b1-4)Glc\", \"Fuc(a1-2)Gal(b1-3)GalNAc\"],\n",
    "                    [\"Neu5Ac(a2-6)Gal(b1-4)Glc\", \"Fuc(a1-2)Gal(a1-3)GalNAc\"],\n",
    "                    [1, 0], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-remainder",
   "metadata": {},
   "source": [
    "## inference\n",
    "<a class=\"anchor\" id=\"inference\"></a>\n",
    ">can be used to analyze trained models, make predictions, or obtain glycan representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-tokyo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans:List[str], model:torch.nn.modules.module.Module,\n",
       ">                      libr:Optional[Dict[str,int]]=None, batch_size:int=32,\n",
       ">                      rep:bool=True, class_list:Optional[List[str]]=None)\n",
       "\n",
       "*Returns a dataframe of learned representations for a list of glycans*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycans | List |  | list of glycans in IUPAC-condensed |\n",
       "| model | Module |  | trained graph neural network for analyzing glycans |\n",
       "| libr | Optional | None | dictionary of form glycoletter:index |\n",
       "| batch_size | int | 32 | batch size used during training |\n",
       "| rep | bool | True | True returns representations, False returns predicted labels |\n",
       "| class_list | Optional | None | list of unique classes to map predictions |\n",
       "| **Returns** | **Union** |  | **dataframe of representations or list of predictions** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### glycans_to_emb\n",
       "\n",
       ">      glycans_to_emb (glycans:List[str], model:torch.nn.modules.module.Module,\n",
       ">                      libr:Optional[Dict[str,int]]=None, batch_size:int=32,\n",
       ">                      rep:bool=True, class_list:Optional[List[str]]=None)\n",
       "\n",
       "*Returns a dataframe of learned representations for a list of glycans*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycans | List |  | list of glycans in IUPAC-condensed |\n",
       "| model | Module |  | trained graph neural network for analyzing glycans |\n",
       "| libr | Optional | None | dictionary of form glycoletter:index |\n",
       "| batch_size | int | 32 | batch size used during training |\n",
       "| rep | bool | True | True returns representations, False returns predicted labels |\n",
       "| class_list | Optional | None | list of unique classes to map predictions |\n",
       "| **Returns** | **Union** |  | **dataframe of representations or list of predictions** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(glycans_to_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot:str, glycans:List[str],\n",
       ">                        model:torch.nn.modules.module.Module,\n",
       ">                        prot_dic:Optional[Dict[str,List[float]]]=None,\n",
       ">                        background_correction:bool=False, correction_df:Optiona\n",
       ">                        l[pandas.core.frame.DataFrame]=None,\n",
       ">                        batch_size:int=128, libr:Optional[Dict[str,int]]=None,\n",
       ">                        sort:bool=True, flex:bool=False)\n",
       "\n",
       "*Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| prot | str |  | protein amino acid sequence |\n",
       "| glycans | List |  | list of glycans in IUPAC-condensed |\n",
       "| model | Module |  | trained LectinOracle-type model |\n",
       "| prot_dic | Optional | None | dict of protein sequence:ESM1b representation |\n",
       "| background_correction | bool | False | whether to correct predictions for background |\n",
       "| correction_df | Optional | None | background prediction for glycans |\n",
       "| batch_size | int | 128 | batch size used during training |\n",
       "| libr | Optional | None | dict of glycoletter:index |\n",
       "| sort | bool | True | whether to sort prediction results descendingly |\n",
       "| flex | bool | False | LectinOracle (False) or LectinOracle_flex (True) |\n",
       "| **Returns** | **DataFrame** |  | **glycan sequences and predicted binding** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_lectin_preds\n",
       "\n",
       ">      get_lectin_preds (prot:str, glycans:List[str],\n",
       ">                        model:torch.nn.modules.module.Module,\n",
       ">                        prot_dic:Optional[Dict[str,List[float]]]=None,\n",
       ">                        background_correction:bool=False, correction_df:Optiona\n",
       ">                        l[pandas.core.frame.DataFrame]=None,\n",
       ">                        batch_size:int=128, libr:Optional[Dict[str,int]]=None,\n",
       ">                        sort:bool=True, flex:bool=False)\n",
       "\n",
       "*Wrapper that uses LectinOracle-type model for predicting binding of protein to glycans*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| prot | str |  | protein amino acid sequence |\n",
       "| glycans | List |  | list of glycans in IUPAC-condensed |\n",
       "| model | Module |  | trained LectinOracle-type model |\n",
       "| prot_dic | Optional | None | dict of protein sequence:ESM1b representation |\n",
       "| background_correction | bool | False | whether to correct predictions for background |\n",
       "| correction_df | Optional | None | background prediction for glycans |\n",
       "| batch_size | int | 128 | batch size used during training |\n",
       "| libr | Optional | None | dict of glycoletter:index |\n",
       "| sort | bool | True | whether to sort prediction results descendingly |\n",
       "| flex | bool | False | LectinOracle (False) or LectinOracle_flex (True) |\n",
       "| **Returns** | **DataFrame** |  | **glycan sequences and predicted binding** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_lectin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots:List[str], model:torch.nn.modules.module.Module,\n",
       ">                         prot_dic:Dict[str,List[float]])\n",
       "\n",
       "*Predicts whether an N-sequon will be glycosylated*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| prots | List | 20 AA + N + 20 AA sequences; replace missing with 'z' |\n",
       "| model | Module | trained NSequonPred-type model |\n",
       "| prot_dic | Dict | dict of protein sequence:ESM1b representation |\n",
       "| **Returns** | **DataFrame** | **protein sequences and predicted likelihood** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_Nsequon_preds\n",
       "\n",
       ">      get_Nsequon_preds (prots:List[str], model:torch.nn.modules.module.Module,\n",
       ">                         prot_dic:Dict[str,List[float]])\n",
       "\n",
       "*Predicts whether an N-sequon will be glycosylated*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| prots | List | 20 AA + N + 20 AA sequences; replace missing with 'z' |\n",
       "| model | Module | trained NSequonPred-type model |\n",
       "| prot_dic | Dict | dict of protein sequence:ESM1b representation |\n",
       "| **Returns** | **DataFrame** | **protein sequences and predicted likelihood** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_Nsequon_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots:List[str],\n",
       ">                                 model:torch.nn.modules.module.Module,\n",
       ">                                 alphabet:Any)\n",
       "\n",
       "*Retrieves ESM1b representations of protein for using them as input for LectinOracle*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| prots | List | list of protein sequences to convert |\n",
       "| model | Module | trained ESM1b model |\n",
       "| alphabet | Any | used for converting sequences |\n",
       "| **Returns** | **Dict** | **dict of protein sequence:ESM1b representation** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_esm1b_representations\n",
       "\n",
       ">      get_esm1b_representations (prots:List[str],\n",
       ">                                 model:torch.nn.modules.module.Module,\n",
       ">                                 alphabet:Any)\n",
       "\n",
       "*Retrieves ESM1b representations of protein for using them as input for LectinOracle*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| prots | List | list of protein sequences to convert |\n",
       "| model | Module | trained ESM1b model |\n",
       "| alphabet | Any | used for converting sequences |\n",
       "| **Returns** | **Dict** | **dict of protein sequence:ESM1b representation** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_esm1b_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-tractor",
   "metadata": {},
   "source": [
    "In order to run `get_esm1b_representations`, you first have to run this snippet:\n",
    "\n",
    "`!pip install fair-esm\n",
    "import esm\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-scheduling",
   "metadata": {},
   "source": [
    "## train_test_split\n",
    ">contains various data split functions to get appropriate training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-effect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in:pandas.core.frame.DataFrame, rank:str='Domain',\n",
       ">                        min_seq:int=5, wildcard_seed:bool=False,\n",
       ">                        wildcard_list:Optional[List[str]]=None,\n",
       ">                        wildcard_name:Optional[str]=None, r:float=0.1,\n",
       ">                        col:str='glycan')\n",
       "\n",
       "*stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df_in | DataFrame |  | dataframe of glycan sequences and taxonomic labels |\n",
       "| rank | str | Domain | taxonomic rank to filter |\n",
       "| min_seq | int | 5 | minimum glycans per class |\n",
       "| wildcard_seed | bool | False | seed wildcard glycoletters |\n",
       "| wildcard_list | Optional | None | glycoletters for wildcard |\n",
       "| wildcard_name | Optional | None | wildcard name in IUPAC |\n",
       "| r | float | 0.1 | replacement rate |\n",
       "| col | str | glycan | column name for glycans |\n",
       "| **Returns** | **Tuple** |  | **train/val splits and mappings** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### hierarchy_filter\n",
       "\n",
       ">      hierarchy_filter (df_in:pandas.core.frame.DataFrame, rank:str='Domain',\n",
       ">                        min_seq:int=5, wildcard_seed:bool=False,\n",
       ">                        wildcard_list:Optional[List[str]]=None,\n",
       ">                        wildcard_name:Optional[str]=None, r:float=0.1,\n",
       ">                        col:str='glycan')\n",
       "\n",
       "*stratified data split in train/test at the taxonomic level, removing duplicate glycans and infrequent classes*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df_in | DataFrame |  | dataframe of glycan sequences and taxonomic labels |\n",
       "| rank | str | Domain | taxonomic rank to filter |\n",
       "| min_seq | int | 5 | minimum glycans per class |\n",
       "| wildcard_seed | bool | False | seed wildcard glycoletters |\n",
       "| wildcard_list | Optional | None | glycoletters for wildcard |\n",
       "| wildcard_name | Optional | None | wildcard name in IUPAC |\n",
       "| r | float | 0.1 | replacement rate |\n",
       "| col | str | glycan | column name for glycans |\n",
       "| **Returns** | **Tuple** |  | **train/val splits and mappings** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(hierarchy_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neu5Ac(a2-8)Neu5Ac(a2-6)[Gal(?1-?)GalNAc(a1-3)]GalNAc', 'Man(a1-2)Man(a1-2)Man(b1-3)GlcNAc(a1-6)Man', 'GlcNAc(b1-2)Man(a1-6)[Man(a1-3)][GlcNAc(b1-4)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'GalNAcOS(b1-4)GlcNAc(b1-2)Man(a1-3)[GalNAcOS(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc', 'Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-4)[Gal(b1-4)GlcNAc(b1-2)]Man(a1-3)[Neu5Ac(a2-3)Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc', 'Neu5Ac(a2-?)Gal(b1-4)[Fuc(a1-3)]GlcNAc(b1-2)Man(a1-?)[Fuc(a1-3)[Gal(b1-4)]GlcNAc(b1-2)Man(a1-?)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', '{Gal(b1-4)GlcNAc(b1-?)}{Gal(b1-4)GlcNAc(b1-?)}{Gal(b1-4)GlcNAc(b1-?)}{Neu5Ac(a2-?)}{Neu5Ac(a2-?)}Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-4)]Man(a1-3)[Gal(b1-4)GlcNAc(b1-2)[Gal(b1-4)GlcNAc(b1-6)]Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Glc(a1-4)Glc(a1-4)[Glc(a1-6)Glc(a1-6)]Glc(a1-4)Glc(a1-4)Glc(a1-4)Glc(a1-4)Glc(a1-4)Glc(a1-4)Glc(a1-4)Glc', 'Fuc(a1-?)Hex(?1-?)[Hex(?1-?)]GalNAc', 'Neu5Ac(a2-?)GalNAc(b1-4)GlcNAc(b1-2)Man(a1-3)[Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y, id_val, class_list, class_converter = hierarchy_filter(df_species,\n",
    "                                                                                       rank = 'Kingdom')\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans:List[str], labels:List[Union[float,int,str]],\n",
       ">                     test_size:float=0.2)\n",
       "\n",
       "*splits glycans and labels into train / test sets*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycans | List |  | list of IUPAC-condensed glycans |\n",
       "| labels | List |  | list of prediction labels |\n",
       "| test_size | float | 0.2 | size of test set |\n",
       "| **Returns** | **Tuple** |  | **train/test splits** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### general_split\n",
       "\n",
       ">      general_split (glycans:List[str], labels:List[Union[float,int,str]],\n",
       ">                     test_size:float=0.2)\n",
       "\n",
       "*splits glycans and labels into train / test sets*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| glycans | List |  | list of IUPAC-condensed glycans |\n",
       "| labels | List |  | list of prediction labels |\n",
       "| test_size | float | 0.2 | size of test set |\n",
       "| **Returns** | **Tuple** |  | **train/test splits** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(general_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-harvest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GlcNAc(b1-2)[GlcNAc(b1-4)]Man(a1-3)[GlcNAc(b1-2)Man(a1-6)][GlcNAc(b1-4)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Fuc(a1-2)[GalNAc(a1-3)]Gal(b1-?)GlcNAc6S(b1-6)[Fuc(a1-2)[GalNAc(a1-3)]Gal(b1-3)]GalNAc', 'Neu5Ac(a2-?)GalNAc(b1-4)GlcNAc(b1-2)Man(a1-3)[Gal(b1-4)[Neu5Ac(a2-?)]GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)[Fuc(a1-6)]GlcNAc', 'Glc(a1-4)Glc(a1-4)[Glc(a1-4)Glc(a1-4)Glc(a1-6)]Glc(a1-4)Glc', 'Gal(b1-4)GlcNAc(b1-2)Man(a1-3)[Gal(b1-4)GlcNAc(b1-2)Man(a1-6)]Man(b1-4)GlcNAc(b1-4)GlcNAc', 'Fuc(a1-2)Gal(b1-4)Glc-ol', 'Neu5Gc(a2-8)Neu5Ac(a2-6)[Gal(b1-3)]GalNAc', 'Glc(b1-4)Rha(b1-3)[Glc(a1-6)]Gal', 'Glc6Ac(b1-2)Glc1Ole6Ac(b1-4)Glc6Ac', 'Neu5Ac(a2-3)[GalNAc(b1-4)]Gal(b1-4)Glc-ol']\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = general_split(df_species.glycan.values.tolist(),\n",
    "                                              df_species.Species.values.tolist())\n",
    "print(train_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-joyce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df:pandas.core.frame.DataFrame, rank:str='Species',\n",
       ">                          glycan_col:str='glycan')\n",
       "\n",
       "*converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | DataFrame |  | dataframe with one glycan-association per row |\n",
       "| rank | str | Species | label column to use |\n",
       "| glycan_col | str | glycan | column with glycan sequences |\n",
       "| **Returns** | **Tuple** |  | **unique glycans and their label vectors** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### prepare_multilabel\n",
       "\n",
       ">      prepare_multilabel (df:pandas.core.frame.DataFrame, rank:str='Species',\n",
       ">                          glycan_col:str='glycan')\n",
       "\n",
       "*converts a one row per glycan-species/tissue/disease association file to a format of one glycan - all associations*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | DataFrame |  | dataframe with one glycan-association per row |\n",
       "| rank | str | Species | label column to use |\n",
       "| glycan_col | str | glycan | column with glycan sequences |\n",
       "| **Returns** | **Tuple** |  | **unique glycans and their label vectors** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(prepare_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlcNAcOS(b1-6)Gal(b1-3)GalNAc\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "glycans, labels = prepare_multilabel(df_species[df_species.Order == 'Carnivora'])\n",
    "print(glycans[50])\n",
    "print(labels[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-montreal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
